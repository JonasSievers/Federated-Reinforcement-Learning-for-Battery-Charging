{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\rs1044\\Documents\\GitHub\\Federated-Reinforcement-Learning-for-Battery-Charging\\.venv\\lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n",
      "WARNING:tensorflow:From c:\\Users\\rs1044\\Documents\\GitHub\\Federated-Reinforcement-Learning-for-Battery-Charging\\.venv\\lib\\site-packages\\tensorflow_probability\\python\\internal\\backend\\numpy\\_utils.py:48: The name tf.logging.TaskLevelStatusMessage is deprecated. Please use tf.compat.v1.logging.TaskLevelStatusMessage instead.\n",
      "\n",
      "WARNING:tensorflow:From c:\\Users\\rs1044\\Documents\\GitHub\\Federated-Reinforcement-Learning-for-Battery-Charging\\.venv\\lib\\site-packages\\tensorflow_probability\\python\\internal\\backend\\numpy\\_utils.py:48: The name tf.control_flow_v2_enabled is deprecated. Please use tf.compat.v1.control_flow_v2_enabled instead.\n",
      "\n",
      "WARNING:tensorflow:From c:\\Users\\rs1044\\Documents\\GitHub\\Federated-Reinforcement-Learning-for-Battery-Charging\\.venv\\lib\\site-packages\\tf_agents\\typing\\types.py:114: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Imports\n",
    "import os\n",
    "import tensorflow as tf\n",
    "\n",
    "import sys\n",
    "sys.path.insert(0, '..')\n",
    "from utils.federatedAggregation import FederatedAggregation\n",
    "from utils.reinforcementLearningHelper import *\n",
    "from utils.federatedLearningHelper import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch size: 1 / State Space: 6 / Action Space: 1 / Upper bound: 2.3\n"
     ]
    }
   ],
   "source": [
    "#Setup Environments of selected buildings for training, evaluation, and testing\n",
    "\n",
    "environments, observation_spec, action_spec  = setup_energymanagement_environments(num_buildings=30)\n",
    "\n",
    "#Check environment setup\n",
    "print(\n",
    "    \"Batch size:\", environments[\"train\"][f\"building_1\"].batch_size, \n",
    "    \"/ State Space: {} / Action Space: {}\".format(observation_spec.shape[0], action_spec.shape[0]),\n",
    "    \"/ Upper bound: {}\".format(round(environments[\"train\"][f\"building_1\"].action_spec().maximum.item(), 3)),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: array([7], dtype=int64),\n",
       " 1: array([16, 17, 21], dtype=int64),\n",
       " 2: array([13, 19, 20], dtype=int64),\n",
       " 3: array([18], dtype=int64),\n",
       " 4: array([ 3,  4,  9, 14, 15, 22, 30], dtype=int64),\n",
       " 5: array([1], dtype=int64),\n",
       " 6: array([6, 8], dtype=int64),\n",
       " 7: array([11], dtype=int64),\n",
       " 8: array([ 5, 12, 23, 24, 25, 26, 27, 28, 29], dtype=int64),\n",
       " 9: array([ 2, 10], dtype=int64)}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Cluster similar buildings (K-Means with DTW)\n",
    "\n",
    "#Set parameter\n",
    "num_clusters = 10 # 2, 6, 10, 12, 14, 16, 18\n",
    "\n",
    "clustered_buildings = load_clustered_buildings(num_clusters)\n",
    "clustered_buildings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup Agent networks\n",
    "federated_rounds = 3\n",
    "batch_size = 128\n",
    "replay_buffer_capacity = 20000 #-> only <18.000 samples per dataset\n",
    "initial_collect_steps = 200 #2000\n",
    "collect_steps_per_iteration = 20 \n",
    "num_iterations = 100 #10000\n",
    "eval_interval = 95 #9999"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\rs1044\\Documents\\GitHub\\Federated-Reinforcement-Learning-for-Battery-Charging\\.venv\\lib\\site-packages\\keras\\src\\backend.py:873: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# FEDERATED LEARNING - Initalization Round 0\n",
    "\n",
    "tf.compat.v1.reset_default_graph()\n",
    "global_step = tf.compat.v1.train.get_or_create_global_step()\n",
    "\n",
    "#Initalize a global model for each Cluster of similar buildings\n",
    "for cluster in range(num_clusters):\n",
    "        \n",
    "        # 1. Build global agent per cluster\n",
    "        first_building_in_cluster = clustered_buildings[cluster][0]\n",
    "        global_ddpg_agent, global_eval_policy, global_collect_policy = initialize_ddpg_agent(\n",
    "                observation_spec=observation_spec, action_spec=action_spec, global_step=global_step, environments=environments,\n",
    "                )\n",
    "\n",
    "        # 2. Initially store weights\n",
    "        model_dir = os.path.join(os.getcwd(), f\"models/cluster_{cluster}/FLround{0}_c{num_clusters}_AvgAgg\")\n",
    "        os.makedirs(model_dir, exist_ok=True)\n",
    "        \n",
    "        save_agent_weights(global_ddpg_agent, model_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cluster 0: Buildings [7] Federated round --- 1 / 3\n",
      "WARNING:tensorflow:From c:\\Users\\rs1044\\Documents\\GitHub\\Federated-Reinforcement-Learning-for-Battery-Charging\\.venv\\lib\\site-packages\\tensorflow\\python\\autograph\\impl\\api.py:377: ReplayBuffer.get_next (from tf_agents.replay_buffers.replay_buffer) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `as_dataset(..., single_deterministic_pass=False) instead.\n",
      "Return:  -19687.035\n",
      "Cluster 1: Buildings [16 17 21] Federated round --- 1 / 3\n",
      "Return:  -642.3784\n",
      "Return:  -19369.805\n",
      "Return:  -18489.107\n",
      "Cluster 2: Buildings [13 19 20] Federated round --- 1 / 3\n",
      "WARNING:tensorflow:5 out of the last 5 calls to <function AverageReturnMetric.reset at 0x0000017077969000> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:5 out of the last 5 calls to <bound method DynamicEpisodeDriver.run of <tf_agents.drivers.dynamic_episode_driver.DynamicEpisodeDriver object at 0x0000017077B8D2D0>> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:5 out of the last 5 calls to <function TFDeque.mean at 0x000001707796AC20> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Return:  -14994.312\n",
      "WARNING:tensorflow:6 out of the last 6 calls to <function AverageReturnMetric.reset at 0x000001707796AC20> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:6 out of the last 6 calls to <bound method DynamicEpisodeDriver.run of <tf_agents.drivers.dynamic_episode_driver.DynamicEpisodeDriver object at 0x00000170794AEB30>> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:6 out of the last 6 calls to <function TFDeque.mean at 0x00000170793E9A20> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Return:  -7541.0674\n",
      "Return:  -4345.847\n",
      "Cluster 3: Buildings [18] Federated round --- 1 / 3\n",
      "Return:  -16413.121\n",
      "Cluster 4: Buildings [ 3  4  9 14 15 22 30] Federated round --- 1 / 3\n",
      "Return:  -23726.002\n",
      "Return:  -11160.158\n",
      "Return:  -11334.476\n",
      "Return:  -1473.2059\n",
      "Return:  -18429.979\n",
      "Return:  -17025.637\n",
      "Return:  -18571.162\n",
      "Cluster 5: Buildings [1] Federated round --- 1 / 3\n",
      "Return:  -5776.559\n",
      "Cluster 6: Buildings [6 8] Federated round --- 1 / 3\n",
      "Return:  -6587.0293\n",
      "Return:  -3736.4692\n",
      "Cluster 7: Buildings [11] Federated round --- 1 / 3\n",
      "Return:  -5603.706\n",
      "Cluster 8: Buildings [ 5 12 23 24 25 26 27 28 29] Federated round --- 1 / 3\n",
      "Return:  -23590.918\n",
      "Return:  -544.7741\n",
      "Return:  -3408.8855\n",
      "Return:  -165011.38\n",
      "Return:  -3340.0242\n",
      "Return:  -2244.8218\n",
      "Return:  -368.5231\n",
      "Return:  -17945.035\n",
      "Return:  -1584.1259\n",
      "Cluster 9: Buildings [ 2 10] Federated round --- 1 / 3\n",
      "Return:  -7514.169\n",
      "Return:  -18900.459\n",
      "Cluster 0: Buildings [7] Federated round --- 2 / 3\n",
      "Return:  -6605.8696\n",
      "Cluster 1: Buildings [16 17 21] Federated round --- 2 / 3\n",
      "Return:  -1823.5441\n",
      "Return:  -7940.3027\n",
      "Return:  -3415.853\n",
      "Cluster 2: Buildings [13 19 20] Federated round --- 2 / 3\n",
      "Return:  -8216.344\n",
      "Return:  -13605.071\n",
      "Return:  -6512.558\n",
      "Cluster 3: Buildings [18] Federated round --- 2 / 3\n",
      "Return:  -6749.242\n",
      "Cluster 4: Buildings [ 3  4  9 14 15 22 30] Federated round --- 2 / 3\n",
      "Return:  -9991.21\n",
      "Return:  -10069.5205\n",
      "Return:  -11662.654\n",
      "Return:  -11165.949\n",
      "Return:  -13743.778\n",
      "Return:  -6625.588\n",
      "Return:  -15705.113\n",
      "Cluster 5: Buildings [1] Federated round --- 2 / 3\n",
      "Return:  1129.0549\n",
      "Cluster 6: Buildings [6 8] Federated round --- 2 / 3\n",
      "Return:  -358.894\n",
      "Return:  -6809.612\n",
      "Cluster 7: Buildings [11] Federated round --- 2 / 3\n",
      "Return:  -3806.0276\n",
      "Cluster 8: Buildings [ 5 12 23 24 25 26 27 28 29] Federated round --- 2 / 3\n",
      "Return:  -12514.716\n",
      "Return:  -142983.23\n",
      "Return:  -8528.073\n",
      "Return:  -3798.667\n",
      "Return:  -14170.049\n",
      "Return:  -5172.637\n",
      "Return:  -7044.34\n",
      "Return:  -5290.9272\n",
      "Return:  -6465.2163\n",
      "Cluster 9: Buildings [ 2 10] Federated round --- 2 / 3\n",
      "Return:  -8049.8154\n",
      "Return:  -6216.264\n",
      "Cluster 0: Buildings [7] Federated round --- 3 / 3\n",
      "Return:  -8238.155\n",
      "Cluster 1: Buildings [16 17 21] Federated round --- 3 / 3\n",
      "Return:  -4971.59\n",
      "Return:  -16370.953\n",
      "Return:  -11458.259\n",
      "Cluster 2: Buildings [13 19 20] Federated round --- 3 / 3\n",
      "Return:  -9230.134\n",
      "Return:  -3032.532\n",
      "Return:  -2187.3115\n",
      "Cluster 3: Buildings [18] Federated round --- 3 / 3\n",
      "Return:  -12071.415\n",
      "Cluster 4: Buildings [ 3  4  9 14 15 22 30] Federated round --- 3 / 3\n",
      "Return:  -656.5388\n",
      "Return:  -5237.8394\n",
      "Return:  -4220.8115\n",
      "Return:  337.05365\n",
      "Return:  -6191.7993\n",
      "Return:  -7358.027\n",
      "Return:  -3136.637\n",
      "Cluster 5: Buildings [1] Federated round --- 3 / 3\n",
      "Return:  -2864.306\n",
      "Cluster 6: Buildings [6 8] Federated round --- 3 / 3\n",
      "Return:  -5078.686\n",
      "Return:  -15047.867\n",
      "Cluster 7: Buildings [11] Federated round --- 3 / 3\n",
      "Return:  -5661.995\n",
      "Cluster 8: Buildings [ 5 12 23 24 25 26 27 28 29] Federated round --- 3 / 3\n",
      "Return:  -2352.7236\n",
      "Return:  -877.6758\n",
      "Return:  -8360.537\n",
      "Return:  557.6948\n",
      "Return:  -8960.519\n",
      "Return:  -5488.2056\n",
      "Return:  -1337.4485\n",
      "Return:  -3226.7124\n",
      "Return:  -7920.684\n",
      "Cluster 9: Buildings [ 2 10] Federated round --- 3 / 3\n",
      "Return:  -4162.768\n",
      "Return:  -9868.629\n"
     ]
    }
   ],
   "source": [
    "#FEDERATED LEARNING - Model training for multiple Rounds\n",
    "\n",
    "#For each federated round and cluster\n",
    "for federated_round  in range(federated_rounds):\n",
    "    for cluster_number, buildings_in_cluster in clustered_buildings.items():\n",
    "\n",
    "        #Iterate through the buildings per cluster\n",
    "        print(f\"Cluster {cluster_number}: Buildings {buildings_in_cluster} Federated round ---\", federated_round+1, f\"/ {federated_rounds}\")\n",
    "        local_storage = {\n",
    "            \"actor_weights\": [], \"critic_weights\": [], \"target_actor_weights\": [], \"target_critic_weights\": [],\"performance_metrics\": []\n",
    "            }\n",
    "        \n",
    "        for building_index in buildings_in_cluster:\n",
    "            \n",
    "            #0. Reset global step\n",
    "            tf.compat.v1.reset_default_graph()\n",
    "            global_step = tf.compat.v1.train.get_or_create_global_step()\n",
    "            \n",
    "            #1. Initalize local agent\n",
    "            local_ddpg_agent, local_eval_policy, local_collect_policy = initialize_ddpg_agent(\n",
    "                observation_spec = observation_spec, action_spec = action_spec,\n",
    "                global_step = global_step, environments = environments,\n",
    "                )\n",
    "            \n",
    "            #2. Set global weights of this training round to agent (loads the weights of last training)\n",
    "            model_dir = os.path.join(os.getcwd(), f\"models/cluster_{cluster_number}/FLround{federated_round}_c{num_clusters}_AvgAgg\")\n",
    "            local_ddpg_agent = set_weights_to_ddpg_agent(local_ddpg_agent, model_dir)\n",
    "            \n",
    "            #3. Prepare training pipeline: Setup iterator, replay buffer, driver\n",
    "            local_iterator, local_collect_driver, local_time_step, local_policy_state = setup_rl_training_pipeline(\n",
    "                local_ddpg_agent, environments[\"train\"][f\"building_{building_index}\"], replay_buffer_capacity,\n",
    "                local_collect_policy, initial_collect_steps, collect_steps_per_iteration, batch_size\n",
    "                )\n",
    "            \n",
    "            #4. Train, evaluate agent and store weights\n",
    "            local_ddpg_agent, local_storage = local_agent_training_and_evaluation(\n",
    "                local_iterator, local_collect_driver, local_time_step, local_policy_state, global_step, \n",
    "                local_ddpg_agent, local_eval_policy, local_storage, building_index, num_iterations, environments\n",
    "                )           \n",
    "\n",
    "        # Performe Federated aggregation\n",
    "        average_actor_weights = FederatedAggregation.federated_weigthed_aggregation(local_storage[\"actor_weights\"], local_storage[\"performance_metrics\"])\n",
    "        average_critic_weights = FederatedAggregation.federated_weigthed_aggregation(local_storage[\"critic_weights\"], local_storage[\"performance_metrics\"]) \n",
    "        average_target_actor_weights = FederatedAggregation.federated_weigthed_aggregation(local_storage[\"target_actor_weights\"], local_storage[\"performance_metrics\"]) \n",
    "        average_target_critic_weights = FederatedAggregation.federated_weigthed_aggregation(local_storage[\"target_critic_weights\"], local_storage[\"performance_metrics\"])    \n",
    "        \n",
    "        #Save federated weights for next round (Round + 1)\n",
    "        model_dir = os.path.join(os.getcwd(), f\"models/cluster_{cluster_number}/FLround{federated_round+1}_c{num_clusters}_AvgAgg\")\n",
    "        os.makedirs(model_dir, exist_ok=True)\n",
    "        save_federated_weights(model_dir, average_actor_weights, average_critic_weights, average_target_actor_weights, average_target_critic_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cluster:  0  - Building:  7  - round:  0\n",
      "WARNING:tensorflow:5 out of the last 104 calls to <bound method DynamicStepDriver.run of <tf_agents.drivers.dynamic_step_driver.DynamicStepDriver object at 0x00000170798F7A90>> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\rs1044\\Documents\\GitHub\\Federated-Reinforcement-Learning-for-Battery-Charging\\src\\notebooks\\..\\utils\\federatedLearningHelper.py:106: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  result_df = pd.concat([result_df, pd.DataFrame({'Building': [building_index], 'Total Profit': [wandb.summary[\"Final Profit\"]]})], ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building:  7  - Total Profit:  -1.145612050882451\n",
      "Cluster:  1  - Building:  16  - round:  0\n",
      "Building:  16  - Total Profit:  -139.64058912392954\n",
      "Cluster:  1  - Building:  17  - round:  0\n",
      "Building:  17  - Total Profit:  -350.52357423626324\n",
      "Cluster:  1  - Building:  21  - round:  0\n",
      "Building:  21  - Total Profit:  -384.6165657383444\n",
      "Cluster:  2  - Building:  13  - round:  0\n",
      "Building:  13  - Total Profit:  -26.238760095354607\n",
      "Cluster:  2  - Building:  19  - round:  0\n",
      "Building:  19  - Total Profit:  -20.789390238927336\n",
      "Cluster:  2  - Building:  20  - round:  0\n",
      "Building:  20  - Total Profit:  -236.07704916209724\n",
      "Cluster:  3  - Building:  18  - round:  0\n",
      "Building:  18  - Total Profit:  -261.353068709773\n",
      "Cluster:  4  - Building:  3  - round:  0\n",
      "Building:  3  - Total Profit:  -3.0832423870524126\n",
      "Cluster:  4  - Building:  4  - round:  0\n",
      "Building:  4  - Total Profit:  -147.23635914446274\n",
      "Cluster:  4  - Building:  9  - round:  0\n",
      "Building:  9  - Total Profit:  -107.72994501903193\n",
      "Cluster:  4  - Building:  14  - round:  0\n",
      "Building:  14  - Total Profit:  -107.23792039281415\n",
      "Cluster:  4  - Building:  15  - round:  0\n",
      "Building:  15  - Total Profit:  -75.36599516384156\n",
      "Cluster:  4  - Building:  22  - round:  0\n",
      "Building:  22  - Total Profit:  -136.4972383874137\n",
      "Cluster:  4  - Building:  30  - round:  0\n",
      "Building:  30  - Total Profit:  -73.46689328663959\n",
      "Cluster:  5  - Building:  1  - round:  0\n",
      "Building:  1  - Total Profit:  12.139182533369775\n",
      "Cluster:  6  - Building:  6  - round:  0\n",
      "Building:  6  - Total Profit:  -545.6154110359741\n",
      "Cluster:  6  - Building:  8  - round:  0\n",
      "Building:  8  - Total Profit:  -574.0208054789366\n",
      "Cluster:  7  - Building:  11  - round:  0\n",
      "Building:  11  - Total Profit:  -172.76456768027842\n",
      "Cluster:  8  - Building:  5  - round:  0\n",
      "Building:  5  - Total Profit:  -183.191697159466\n",
      "Cluster:  8  - Building:  12  - round:  0\n",
      "Building:  12  - Total Profit:  -216.94495960019432\n",
      "Cluster:  8  - Building:  23  - round:  0\n",
      "Building:  23  - Total Profit:  -136.88148812671704\n",
      "Cluster:  8  - Building:  24  - round:  0\n",
      "Building:  24  - Total Profit:  175.91416984243585\n",
      "Cluster:  8  - Building:  25  - round:  0\n",
      "Building:  25  - Total Profit:  -279.0340036928234\n",
      "Cluster:  8  - Building:  26  - round:  0\n",
      "Building:  26  - Total Profit:  -357.94612125332037\n",
      "Cluster:  8  - Building:  27  - round:  0\n",
      "Building:  27  - Total Profit:  -190.32853877391196\n",
      "Cluster:  8  - Building:  28  - round:  0\n",
      "Building:  28  - Total Profit:  -109.21029186942532\n",
      "Cluster:  8  - Building:  29  - round:  0\n",
      "Building:  29  - Total Profit:  -152.853055066385\n",
      "Cluster:  9  - Building:  2  - round:  0\n",
      "Building:  2  - Total Profit:  -183.38998412174504\n",
      "Cluster:  9  - Building:  10  - round:  0\n",
      "Building:  10  - Total Profit:  -145.86676754361204\n"
     ]
    }
   ],
   "source": [
    "# LOCAL REFITTING AND EVALUATION\n",
    "\n",
    "best_federated_round = 3\n",
    "num_rounds=1\n",
    "num_test_iterations = 200\n",
    "\n",
    "result_df = pd.DataFrame(columns=['Building', 'Total Profit'])\n",
    "\n",
    "for cluster_number, buildings_in_cluster in clustered_buildings.items():\n",
    "    for building_index in buildings_in_cluster:\n",
    "        \n",
    "        for round in range(num_rounds):\n",
    "            print(\"Cluster: \", cluster_number, \" - Building: \", building_index, \" - round: \", round)\n",
    "            \n",
    "            #0. Reset global step\n",
    "            tf.compat.v1.reset_default_graph()\n",
    "            global_step = tf.compat.v1.train.get_or_create_global_step()\n",
    "\n",
    "            #1. Initalize local agent\n",
    "            tf_ddpg_agent, eval_policy, collect_policy = initialize_ddpg_agent(\n",
    "                observation_spec = observation_spec, action_spec = action_spec,\n",
    "                global_step = global_step, environments = environments,\n",
    "                )\n",
    "            \n",
    "            #2. Set global weights of this training round to agent (loads the weights of last training)\n",
    "            model_dir = os.path.join(os.getcwd(), f\"models/cluster_{cluster_number}/FLround{best_federated_round}_c{num_clusters}_AvgAgg\")\n",
    "            tf_agent = set_weights_to_ddpg_agent(tf_ddpg_agent, model_dir)\n",
    "\n",
    "            #3. Prepare training pipeline: Setup iterator, replay buffer, driver\n",
    "            iterator, collect_driver, time_step, policy_state = setup_rl_training_pipeline(\n",
    "                tf_ddpg_agent, environments[\"train\"][f\"building_{building_index}\"], replay_buffer_capacity,\n",
    "                collect_policy, initial_collect_steps, collect_steps_per_iteration, batch_size\n",
    "                )\n",
    "            \n",
    "            #4. Setup wandb logging\n",
    "            artifact = initialize_wandb_logging(name=f\"Exp_building{building_index}_rd{round}\", num_iterations=num_iterations)\n",
    "            \n",
    "            #5. Train, evaluate agent and store weights\n",
    "            result_df, metrics = agent_retraining_and_evaluation(global_step, num_test_iterations, collect_driver, \n",
    "                time_step, policy_state, iterator, tf_ddpg_agent, eval_policy, building_index, result_df, eval_interval, environments)\n",
    "            \n",
    "            #6. End and log wandb\n",
    "            end_and_log_wandb(metrics, artifact)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Building</th>\n",
       "      <th>Total Profit</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7</td>\n",
       "      <td>-1.145612</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>16</td>\n",
       "      <td>-139.640589</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>17</td>\n",
       "      <td>-350.523574</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>21</td>\n",
       "      <td>-384.616566</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>13</td>\n",
       "      <td>-26.238760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>19</td>\n",
       "      <td>-20.789390</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>20</td>\n",
       "      <td>-236.077049</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>18</td>\n",
       "      <td>-261.353069</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>3</td>\n",
       "      <td>-3.083242</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>4</td>\n",
       "      <td>-147.236359</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>9</td>\n",
       "      <td>-107.729945</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>14</td>\n",
       "      <td>-107.237920</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>15</td>\n",
       "      <td>-75.365995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>22</td>\n",
       "      <td>-136.497238</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>30</td>\n",
       "      <td>-73.466893</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>1</td>\n",
       "      <td>12.139183</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>6</td>\n",
       "      <td>-545.615411</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>8</td>\n",
       "      <td>-574.020805</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>11</td>\n",
       "      <td>-172.764568</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>5</td>\n",
       "      <td>-183.191697</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>12</td>\n",
       "      <td>-216.944960</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>23</td>\n",
       "      <td>-136.881488</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>24</td>\n",
       "      <td>175.914170</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>25</td>\n",
       "      <td>-279.034004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>26</td>\n",
       "      <td>-357.946121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>27</td>\n",
       "      <td>-190.328539</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>28</td>\n",
       "      <td>-109.210292</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>29</td>\n",
       "      <td>-152.853055</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>2</td>\n",
       "      <td>-183.389984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>10</td>\n",
       "      <td>-145.866768</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Building  Total Profit\n",
       "0         7     -1.145612\n",
       "1        16   -139.640589\n",
       "2        17   -350.523574\n",
       "3        21   -384.616566\n",
       "4        13    -26.238760\n",
       "5        19    -20.789390\n",
       "6        20   -236.077049\n",
       "7        18   -261.353069\n",
       "8         3     -3.083242\n",
       "9         4   -147.236359\n",
       "10        9   -107.729945\n",
       "11       14   -107.237920\n",
       "12       15    -75.365995\n",
       "13       22   -136.497238\n",
       "14       30    -73.466893\n",
       "15        1     12.139183\n",
       "16        6   -545.615411\n",
       "17        8   -574.020805\n",
       "18       11   -172.764568\n",
       "19        5   -183.191697\n",
       "20       12   -216.944960\n",
       "21       23   -136.881488\n",
       "22       24    175.914170\n",
       "23       25   -279.034004\n",
       "24       26   -357.946121\n",
       "25       27   -190.328539\n",
       "26       28   -109.210292\n",
       "27       29   -152.853055\n",
       "28        2   -183.389984\n",
       "29       10   -145.866768"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save results\n",
    "result_df.rename(columns={'Total Profit': 'Profit'}, inplace=True)\n",
    "result_df['Setup'] = f'cluster{num_clusters}'\n",
    "result_df.index.name = 'Building_nr'\n",
    "result_df.reset_index(inplace=True, drop=True)\n",
    "os.makedirs('results', exist_ok=True)\n",
    "result_df.to_csv(f'results/results_clusters{num_clusters}_df.csv', index=False)\n",
    "print(\"Final reuslt - clusters \", num_clusters, \": \", result_df[\"Profit\"].sum())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
