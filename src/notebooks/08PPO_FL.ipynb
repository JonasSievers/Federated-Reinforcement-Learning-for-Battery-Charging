{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\rs1044\\Documents\\GitHub\\Federated-Reinforcement-Learning-for-Battery-Charging\\.venv\\lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n",
      "WARNING:tensorflow:From c:\\Users\\rs1044\\Documents\\GitHub\\Federated-Reinforcement-Learning-for-Battery-Charging\\.venv\\lib\\site-packages\\tensorflow_probability\\python\\internal\\backend\\numpy\\_utils.py:48: The name tf.logging.TaskLevelStatusMessage is deprecated. Please use tf.compat.v1.logging.TaskLevelStatusMessage instead.\n",
      "\n",
      "WARNING:tensorflow:From c:\\Users\\rs1044\\Documents\\GitHub\\Federated-Reinforcement-Learning-for-Battery-Charging\\.venv\\lib\\site-packages\\tensorflow_probability\\python\\internal\\backend\\numpy\\_utils.py:48: The name tf.control_flow_v2_enabled is deprecated. Please use tf.compat.v1.control_flow_v2_enabled instead.\n",
      "\n",
      "WARNING:tensorflow:From c:\\Users\\rs1044\\Documents\\GitHub\\Federated-Reinforcement-Learning-for-Battery-Charging\\.venv\\lib\\site-packages\\tf_agents\\typing\\types.py:114: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Imports\n",
    "import os\n",
    "import tensorflow as tf\n",
    "\n",
    "import sys\n",
    "sys.path.insert(0, '..')\n",
    "from utils.federatedAggregation import FederatedAggregation\n",
    "from utils.reinforcementLearningHelper import *\n",
    "from utils.federatedLearningHelper import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch size: 1 / State Space: 6 / Action Space: 1 / Upper bound: 2.3\n"
     ]
    }
   ],
   "source": [
    "#Setup Environments of selected buildings for training, evaluation, and testing\n",
    "\n",
    "environments, observation_spec, action_spec  = setup_energymanagement_environments(num_buildings=30)\n",
    "\n",
    "#Check environment setup\n",
    "print(\n",
    "    \"Batch size:\", environments[\"train\"][f\"building_1\"].batch_size, \n",
    "    \"/ State Space: {} / Action Space: {}\".format(observation_spec.shape[0], action_spec.shape[0]),\n",
    "    \"/ Upper bound: {}\".format(round(environments[\"train\"][f\"building_1\"].action_spec().maximum.item(), 3)),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: array([7], dtype=int64),\n",
       " 1: array([16, 17, 21], dtype=int64),\n",
       " 2: array([13, 19, 20], dtype=int64),\n",
       " 3: array([18], dtype=int64),\n",
       " 4: array([ 3,  4,  9, 14, 15, 22, 30], dtype=int64),\n",
       " 5: array([1], dtype=int64),\n",
       " 6: array([6, 8], dtype=int64),\n",
       " 7: array([11], dtype=int64),\n",
       " 8: array([ 5, 12, 23, 24, 25, 26, 27, 28, 29], dtype=int64),\n",
       " 9: array([ 2, 10], dtype=int64)}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Cluster similar buildings (K-Means with DTW)\n",
    "\n",
    "#Set parameter\n",
    "num_clusters = 10 # 2, 6, 10, 12, 14, 16, 18\n",
    "\n",
    "clustered_buildings = load_clustered_buildings(num_clusters)\n",
    "clustered_buildings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup Agent networks\n",
    "federated_rounds = 3\n",
    "batch_size = 128\n",
    "replay_buffer_capacity = 20000 #-> only <18.000 samples per dataset\n",
    "initial_collect_steps = 200 #2000\n",
    "collect_steps_per_iteration = 20 \n",
    "num_iterations = 100 #10000\n",
    "eval_interval = 95 #9999"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\rs1044\\Documents\\GitHub\\Federated-Reinforcement-Learning-for-Battery-Charging\\.venv\\lib\\site-packages\\keras\\src\\backend.py:873: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# FEDERATED LEARNING - Initalization Round 0\n",
    "\n",
    "tf.compat.v1.reset_default_graph()\n",
    "global_step = tf.compat.v1.train.get_or_create_global_step()\n",
    "\n",
    "#Initalize a global model for each Cluster of similar buildings\n",
    "for cluster in range(num_clusters):\n",
    "        \n",
    "        # 1. Build global agent per cluster\n",
    "        first_building_in_cluster = clustered_buildings[cluster][0]\n",
    "        global_ppo_agent, global_eval_policy, global_collect_policy = initialize_ppo_agent(\n",
    "                observation_spec=observation_spec, action_spec=action_spec, global_step=global_step, environments=environments,\n",
    "                )\n",
    "\n",
    "        # 2. Initially store weights\n",
    "        model_dir = os.path.join(os.getcwd(), f\"models/ppo/cluster_{cluster}/FLround{0}_c{num_clusters}_AvgAgg\")\n",
    "        os.makedirs(model_dir, exist_ok=True)\n",
    "        \n",
    "        save_ppo_weights(global_ppo_agent, model_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cluster 0: Buildings [7] Federated round --- 1 / 3\n",
      "WARNING:tensorflow:From c:\\Users\\rs1044\\Documents\\GitHub\\Federated-Reinforcement-Learning-for-Battery-Charging\\.venv\\lib\\site-packages\\tensorflow\\python\\autograph\\impl\\api.py:377: ReplayBuffer.get_next (from tf_agents.replay_buffers.replay_buffer) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `as_dataset(..., single_deterministic_pass=False) instead.\n",
      "Return:  -74047.695\n",
      "Cluster 1: Buildings [16 17 21] Federated round --- 1 / 3\n",
      "Return:  -37190.617\n",
      "Return:  -704.67554\n",
      "Return:  -51346.832\n",
      "Cluster 2: Buildings [13 19 20] Federated round --- 1 / 3\n",
      "WARNING:tensorflow:5 out of the last 5 calls to <function AverageReturnMetric.reset at 0x000001D913E28DC0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:5 out of the last 5 calls to <bound method DynamicEpisodeDriver.run of <tf_agents.drivers.dynamic_episode_driver.DynamicEpisodeDriver object at 0x000001D915472770>> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:5 out of the last 5 calls to <function TFDeque.mean at 0x000001D914052CB0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Return:  -84010.32\n",
      "WARNING:tensorflow:6 out of the last 6 calls to <function AverageReturnMetric.reset at 0x000001D93FB29900> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:6 out of the last 6 calls to <bound method DynamicEpisodeDriver.run of <tf_agents.drivers.dynamic_episode_driver.DynamicEpisodeDriver object at 0x000001D91437E9E0>> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:6 out of the last 6 calls to <function TFDeque.mean at 0x000001D93FCCD510> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Return:  -82364.055\n",
      "Return:  -84678.09\n",
      "Cluster 3: Buildings [18] Federated round --- 1 / 3\n",
      "Return:  -47902.453\n",
      "Cluster 4: Buildings [ 3  4  9 14 15 22 30] Federated round --- 1 / 3\n",
      "Return:  -88413.81\n",
      "Return:  -88689.38\n",
      "Return:  -86646.984\n",
      "Return:  -90582.08\n",
      "Return:  -92183.29\n",
      "Return:  -88065.57\n",
      "Return:  -88133.18\n",
      "Cluster 5: Buildings [1] Federated round --- 1 / 3\n",
      "Return:  -838.1006\n",
      "Cluster 6: Buildings [6 8] Federated round --- 1 / 3\n",
      "Return:  -45855.32\n",
      "Return:  -70924.55\n",
      "Cluster 7: Buildings [11] Federated round --- 1 / 3\n",
      "Return:  -22786.838\n",
      "Cluster 8: Buildings [ 5 12 23 24 25 26 27 28 29] Federated round --- 1 / 3\n",
      "Return:  -120049.664\n",
      "Return:  -120125.016\n",
      "Return:  -120233.234\n",
      "Return:  -151778.22\n",
      "Return:  -120087.21\n",
      "Return:  -123093.04\n",
      "Return:  -119027.3\n",
      "Return:  -121641.68\n",
      "Return:  -127919.086\n",
      "Cluster 9: Buildings [ 2 10] Federated round --- 1 / 3\n",
      "Return:  -45842.08\n",
      "Return:  -45225.61\n",
      "Cluster 0: Buildings [7] Federated round --- 2 / 3\n",
      "Return:  -76302.414\n",
      "Cluster 1: Buildings [16 17 21] Federated round --- 2 / 3\n",
      "Return:  -40703.145\n",
      "Return:  -78766.64\n",
      "Return:  -80688.586\n",
      "Cluster 2: Buildings [13 19 20] Federated round --- 2 / 3\n",
      "Return:  -93612.72\n",
      "Return:  -92690.85\n",
      "Return:  -95144.555\n",
      "Cluster 3: Buildings [18] Federated round --- 2 / 3\n",
      "Return:  -62635.56\n",
      "Cluster 4: Buildings [ 3  4  9 14 15 22 30] Federated round --- 2 / 3\n",
      "Return:  -123807.695\n",
      "Return:  -117707.266\n",
      "Return:  -123511.6\n",
      "Return:  -120578.49\n",
      "Return:  -122714.03\n",
      "Return:  -118830.92\n",
      "Return:  -124438.75\n",
      "Cluster 5: Buildings [1] Federated round --- 2 / 3\n",
      "Return:  -39115.766\n",
      "Cluster 6: Buildings [6 8] Federated round --- 2 / 3\n",
      "Return:  -88407.016\n",
      "Return:  -77084.03\n",
      "Cluster 7: Buildings [11] Federated round --- 2 / 3\n",
      "Return:  -28033.473\n",
      "Cluster 8: Buildings [ 5 12 23 24 25 26 27 28 29] Federated round --- 2 / 3\n",
      "Return:  -185648.28\n",
      "Return:  -187045.53\n",
      "Return:  -187021.55\n",
      "Return:  -185239.23\n",
      "Return:  -187104.81\n",
      "Return:  -186198.52\n",
      "Return:  -187767.28\n",
      "Return:  -185740.06\n",
      "Return:  -187317.3\n",
      "Cluster 9: Buildings [ 2 10] Federated round --- 2 / 3\n",
      "Return:  -98102.6\n",
      "Return:  -94278.41\n",
      "Cluster 0: Buildings [7] Federated round --- 3 / 3\n",
      "Return:  -103882.73\n",
      "Cluster 1: Buildings [16 17 21] Federated round --- 3 / 3\n",
      "Return:  -36342.348\n",
      "Return:  -37319.63\n",
      "Return:  -19223.717\n",
      "Cluster 2: Buildings [13 19 20] Federated round --- 3 / 3\n",
      "Return:  -110578.88\n",
      "Return:  -116567.945\n",
      "Return:  -118376.914\n",
      "Cluster 3: Buildings [18] Federated round --- 3 / 3\n",
      "Return:  -59460.03\n",
      "Cluster 4: Buildings [ 3  4  9 14 15 22 30] Federated round --- 3 / 3\n",
      "Return:  -183194.28\n",
      "Return:  -179685.9\n",
      "Return:  -176992.38\n",
      "Return:  -178028.42\n",
      "Return:  -179823.8\n",
      "Return:  -176085.72\n",
      "Return:  -181826.28\n",
      "Cluster 5: Buildings [1] Federated round --- 3 / 3\n",
      "Return:  -22717.986\n",
      "Cluster 6: Buildings [6 8] Federated round --- 3 / 3\n",
      "Return:  -82291.62\n",
      "Return:  -72203.73\n",
      "Cluster 7: Buildings [11] Federated round --- 3 / 3\n",
      "Return:  -47633.633\n",
      "Cluster 8: Buildings [ 5 12 23 24 25 26 27 28 29] Federated round --- 3 / 3\n",
      "Return:  -190798.11\n",
      "Return:  -191664.06\n",
      "Return:  -191679.56\n",
      "Return:  -189399.78\n",
      "Return:  -191435.2\n",
      "Return:  -190769.25\n",
      "Return:  -191832.31\n",
      "Return:  -190924.78\n",
      "Return:  -190544.05\n",
      "Cluster 9: Buildings [ 2 10] Federated round --- 3 / 3\n",
      "Return:  -115658.51\n",
      "Return:  -104470.67\n"
     ]
    }
   ],
   "source": [
    "#FEDERATED LEARNING - Model training for multiple Rounds\n",
    "\n",
    "#For each federated round and cluster\n",
    "for federated_round  in range(federated_rounds):\n",
    "    for cluster_number, buildings_in_cluster in clustered_buildings.items():\n",
    "\n",
    "        #Iterate through the buildings per cluster\n",
    "        print(f\"Cluster {cluster_number}: Buildings {buildings_in_cluster} Federated round ---\", federated_round+1, f\"/ {federated_rounds}\")\n",
    "        local_storage = {\n",
    "            \"actor_weights\": [], \"value_weights\": [], \"performance_metrics\": []\n",
    "            }\n",
    "        \n",
    "        for building_index in buildings_in_cluster:\n",
    "            \n",
    "            #0. Reset global step\n",
    "            tf.compat.v1.reset_default_graph()\n",
    "            global_step = tf.compat.v1.train.get_or_create_global_step()\n",
    "            \n",
    "            #1. Initalize local agent\n",
    "            local_ppo_agent, local_eval_policy, local_collect_policy = initialize_ppo_agent(\n",
    "                observation_spec = observation_spec, action_spec = action_spec,\n",
    "                global_step = global_step, environments = environments,\n",
    "                )\n",
    "            \n",
    "            #2. Set global weights of this training round to agent (loads the weights of last training)\n",
    "            model_dir = os.path.join(os.getcwd(), f\"models/ppo/cluster_{cluster_number}/FLround{federated_round}_c{num_clusters}_AvgAgg\")\n",
    "            local_ppo_agent = set_weights_to_ppo_agent(local_ppo_agent, model_dir)\n",
    "            \n",
    "            #3. Prepare training pipeline: Setup iterator, replay buffer, driver\n",
    "            local_iterator, local_collect_driver, local_time_step, local_policy_state = setup_rl_training_pipeline(\n",
    "                local_ppo_agent, environments[\"train\"][f\"building_{building_index}\"], replay_buffer_capacity,\n",
    "                local_collect_policy, initial_collect_steps, collect_steps_per_iteration, batch_size\n",
    "                )\n",
    "            \n",
    "            #4. Train, evaluate agent and store weights\n",
    "            local_ppo_agent, local_storage = local_agent_training_and_evaluation(\n",
    "                local_iterator, local_collect_driver, local_time_step, local_policy_state, global_step, \n",
    "                local_ppo_agent, local_eval_policy, local_storage, building_index, num_iterations, environments, agent_type=\"ppo\"\n",
    "                )           \n",
    "\n",
    "        # Performe Federated aggregation\n",
    "        average_actor_weights = FederatedAggregation.federated_weigthed_aggregation(local_storage[\"actor_weights\"], local_storage[\"performance_metrics\"])\n",
    "        average_value_weights = FederatedAggregation.federated_weigthed_aggregation(local_storage[\"value_weights\"], local_storage[\"performance_metrics\"]) \n",
    "        \n",
    "        #Save federated weights for next round (Round + 1)\n",
    "        model_dir = os.path.join(os.getcwd(), f\"models/ppo/cluster_{cluster_number}/FLround{federated_round+1}_c{num_clusters}_AvgAgg\")\n",
    "        os.makedirs(model_dir, exist_ok=True)\n",
    "        save_federated_ppo_weights(model_dir, average_actor_weights, average_value_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cluster:  0  - Building:  7  - round:  0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\rs1044\\Documents\\GitHub\\Federated-Reinforcement-Learning-for-Battery-Charging\\src\\notebooks\\..\\utils\\reinforcementLearningHelper.py:338: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  result_df = pd.concat([result_df, pd.DataFrame({'Building': [building_index], 'Total Profit': [wandb.summary[\"Final Profit\"]]})], ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building:  7  - Total Profit:  -32.98025289999993\n",
      "Cluster:  1  - Building:  16  - round:  0\n",
      "Building:  16  - Total Profit:  -161.0366269000002\n",
      "Cluster:  1  - Building:  17  - round:  0\n",
      "Building:  17  - Total Profit:  -368.11111181999956\n",
      "Cluster:  1  - Building:  21  - round:  0\n",
      "Building:  21  - Total Profit:  -412.2055835700018\n",
      "Cluster:  2  - Building:  13  - round:  0\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[7], line 39\u001b[0m\n\u001b[0;32m     36\u001b[0m artifact \u001b[38;5;241m=\u001b[39m initialize_wandb_logging(name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExp_building\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mbuilding_index\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_rd\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mround\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, num_iterations\u001b[38;5;241m=\u001b[39mnum_iterations)\n\u001b[0;32m     38\u001b[0m \u001b[38;5;66;03m#5. Train, evaluate agent and store weights\u001b[39;00m\n\u001b[1;32m---> 39\u001b[0m result_df, metrics \u001b[38;5;241m=\u001b[39m \u001b[43magent_training_and_evaluation\u001b[49m\u001b[43m(\u001b[49m\u001b[43mglobal_step\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_test_iterations\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcollect_driver\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m     40\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtime_step\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpolicy_state\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43miterator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtf_ppo_agent\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43meval_policy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbuilding_index\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mresult_df\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43meval_interval\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43menvironments\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     42\u001b[0m \u001b[38;5;66;03m#6. End and log wandb\u001b[39;00m\n\u001b[0;32m     43\u001b[0m end_and_log_wandb(metrics, artifact)\n",
      "File \u001b[1;32mc:\\Users\\rs1044\\Documents\\GitHub\\Federated-Reinforcement-Learning-for-Battery-Charging\\src\\notebooks\\..\\utils\\reinforcementLearningHelper.py:337\u001b[0m, in \u001b[0;36magent_training_and_evaluation\u001b[1;34m(global_step, num_test_iterations, collect_driver, time_step, policy_state, iterator, tf_agent, eval_policy, building_index, result_df, eval_interval, environments)\u001b[0m\n\u001b[0;32m    334\u001b[0m         wandb\u001b[38;5;241m.\u001b[39mlog(metrics)\n\u001b[0;32m    336\u001b[0m \u001b[38;5;66;03m#Testing\u001b[39;00m\n\u001b[1;32m--> 337\u001b[0m test_metrics \u001b[38;5;241m=\u001b[39m \u001b[43mmetric_utils\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43meager_compute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtest_metrics\u001b[49m\u001b[43m,\u001b[49m\u001b[43menvironments\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtest\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mbuilding_\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mbuilding_index\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43meval_policy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_step\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mglobal_step\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    338\u001b[0m result_df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mconcat([result_df, pd\u001b[38;5;241m.\u001b[39mDataFrame({\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mBuilding\u001b[39m\u001b[38;5;124m'\u001b[39m: [building_index], \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTotal Profit\u001b[39m\u001b[38;5;124m'\u001b[39m: [wandb\u001b[38;5;241m.\u001b[39msummary[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFinal Profit\u001b[39m\u001b[38;5;124m\"\u001b[39m]]})], ignore_index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m    339\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mBuilding: \u001b[39m\u001b[38;5;124m'\u001b[39m, building_index, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m - Total Profit: \u001b[39m\u001b[38;5;124m'\u001b[39m, wandb\u001b[38;5;241m.\u001b[39msummary[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFinal Profit\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n",
      "File \u001b[1;32mc:\\Users\\rs1044\\Documents\\GitHub\\Federated-Reinforcement-Learning-for-Battery-Charging\\.venv\\lib\\site-packages\\gin\\config.py:1582\u001b[0m, in \u001b[0;36m_make_gin_wrapper.<locals>.gin_wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m   1579\u001b[0m new_kwargs\u001b[38;5;241m.\u001b[39mupdate(kwargs)\n\u001b[0;32m   1581\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1582\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39mnew_args, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mnew_kwargs)\n\u001b[0;32m   1583\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:  \u001b[38;5;66;03m# pylint: disable=broad-except\u001b[39;00m\n\u001b[0;32m   1584\u001b[0m   err_str \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\rs1044\\Documents\\GitHub\\Federated-Reinforcement-Learning-for-Battery-Charging\\.venv\\lib\\site-packages\\tf_agents\\eval\\metric_utils.py:164\u001b[0m, in \u001b[0;36meager_compute\u001b[1;34m(metrics, environment, policy, num_episodes, train_step, summary_writer, summary_prefix, use_function)\u001b[0m\n\u001b[0;32m    160\u001b[0m driver \u001b[38;5;241m=\u001b[39m dynamic_episode_driver\u001b[38;5;241m.\u001b[39mDynamicEpisodeDriver(\n\u001b[0;32m    161\u001b[0m     environment, policy, observers\u001b[38;5;241m=\u001b[39mmetrics, num_episodes\u001b[38;5;241m=\u001b[39mnum_episodes\n\u001b[0;32m    162\u001b[0m )\n\u001b[0;32m    163\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m use_function:\n\u001b[1;32m--> 164\u001b[0m   \u001b[43mcommon\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunction\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdriver\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtime_step\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpolicy_state\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    165\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    166\u001b[0m   driver\u001b[38;5;241m.\u001b[39mrun(time_step, policy_state)\n",
      "File \u001b[1;32mc:\\Users\\rs1044\\Documents\\GitHub\\Federated-Reinforcement-Learning-for-Battery-Charging\\.venv\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32mc:\\Users\\rs1044\\Documents\\GitHub\\Federated-Reinforcement-Learning-for-Battery-Charging\\.venv\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:832\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    829\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    831\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[1;32m--> 832\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m    834\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[0;32m    835\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[1;32mc:\\Users\\rs1044\\Documents\\GitHub\\Federated-Reinforcement-Learning-for-Battery-Charging\\.venv\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:918\u001b[0m, in \u001b[0;36mFunction._call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    912\u001b[0m   \u001b[38;5;66;03m# If we did not create any variables the trace we have is good enough.\u001b[39;00m\n\u001b[0;32m    913\u001b[0m   filtered_flat_args \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    914\u001b[0m       \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_concrete_variable_creation_fn\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39munpack_inputs(\n\u001b[0;32m    915\u001b[0m           bound_args\n\u001b[0;32m    916\u001b[0m       )\n\u001b[0;32m    917\u001b[0m   )\n\u001b[1;32m--> 918\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_concrete_variable_creation_fn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# pylint: disable=protected-access\u001b[39;49;00m\n\u001b[0;32m    919\u001b[0m \u001b[43m      \u001b[49m\u001b[43mfiltered_flat_args\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    920\u001b[0m \u001b[43m      \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_concrete_variable_creation_fn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcaptured_inputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    921\u001b[0m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    923\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfn_with_cond\u001b[39m(inner_args, inner_kwds):\n\u001b[0;32m    924\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Conditionally runs initialization if it's needed.\"\"\"\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\rs1044\\Documents\\GitHub\\Federated-Reinforcement-Learning-for-Battery-Charging\\.venv\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\concrete_function.py:1323\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[1;34m(self, tensor_inputs, captured_inputs)\u001b[0m\n\u001b[0;32m   1319\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[0;32m   1320\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[0;32m   1321\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[0;32m   1322\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[1;32m-> 1323\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inference_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_preflattened\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1324\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[0;32m   1325\u001b[0m     args,\n\u001b[0;32m   1326\u001b[0m     possible_gradient_type,\n\u001b[0;32m   1327\u001b[0m     executing_eagerly)\n\u001b[0;32m   1328\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
      "File \u001b[1;32mc:\\Users\\rs1044\\Documents\\GitHub\\Federated-Reinforcement-Learning-for-Battery-Charging\\.venv\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\atomic_function.py:216\u001b[0m, in \u001b[0;36mAtomicFunction.call_preflattened\u001b[1;34m(self, args)\u001b[0m\n\u001b[0;32m    214\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcall_preflattened\u001b[39m(\u001b[38;5;28mself\u001b[39m, args: Sequence[core\u001b[38;5;241m.\u001b[39mTensor]) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[0;32m    215\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Calls with flattened tensor inputs and returns the structured output.\"\"\"\u001b[39;00m\n\u001b[1;32m--> 216\u001b[0m   flat_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_flat\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    217\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mpack_output(flat_outputs)\n",
      "File \u001b[1;32mc:\\Users\\rs1044\\Documents\\GitHub\\Federated-Reinforcement-Learning-for-Battery-Charging\\.venv\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\atomic_function.py:251\u001b[0m, in \u001b[0;36mAtomicFunction.call_flat\u001b[1;34m(self, *args)\u001b[0m\n\u001b[0;32m    249\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m record\u001b[38;5;241m.\u001b[39mstop_recording():\n\u001b[0;32m    250\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mexecuting_eagerly():\n\u001b[1;32m--> 251\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_bound_context\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    252\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    253\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    254\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunction_type\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mflat_outputs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    255\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    256\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    257\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m make_call_op_in_graph(\n\u001b[0;32m    258\u001b[0m         \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    259\u001b[0m         \u001b[38;5;28mlist\u001b[39m(args),\n\u001b[0;32m    260\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mfunction_call_options\u001b[38;5;241m.\u001b[39mas_attrs(),\n\u001b[0;32m    261\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\rs1044\\Documents\\GitHub\\Federated-Reinforcement-Learning-for-Battery-Charging\\.venv\\lib\\site-packages\\tensorflow\\python\\eager\\context.py:1486\u001b[0m, in \u001b[0;36mContext.call_function\u001b[1;34m(self, name, tensor_inputs, num_outputs)\u001b[0m\n\u001b[0;32m   1484\u001b[0m cancellation_context \u001b[38;5;241m=\u001b[39m cancellation\u001b[38;5;241m.\u001b[39mcontext()\n\u001b[0;32m   1485\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cancellation_context \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 1486\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m \u001b[43mexecute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1487\u001b[0m \u001b[43m      \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mutf-8\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1488\u001b[0m \u001b[43m      \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1489\u001b[0m \u001b[43m      \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtensor_inputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1490\u001b[0m \u001b[43m      \u001b[49m\u001b[43mattrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1491\u001b[0m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1492\u001b[0m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1493\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1494\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[0;32m   1495\u001b[0m       name\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m   1496\u001b[0m       num_outputs\u001b[38;5;241m=\u001b[39mnum_outputs,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1500\u001b[0m       cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_context,\n\u001b[0;32m   1501\u001b[0m   )\n",
      "File \u001b[1;32mc:\\Users\\rs1044\\Documents\\GitHub\\Federated-Reinforcement-Learning-for-Battery-Charging\\.venv\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py:53\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     51\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     52\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[1;32m---> 53\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     54\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     55\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     56\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# LOCAL REFITTING AND EVALUATION\n",
    "\n",
    "best_federated_round = 3\n",
    "num_rounds=1\n",
    "num_test_iterations = 200\n",
    "\n",
    "result_df = pd.DataFrame(columns=['Building', 'Total Profit'])\n",
    "\n",
    "for cluster_number, buildings_in_cluster in clustered_buildings.items():\n",
    "    for building_index in buildings_in_cluster:\n",
    "        \n",
    "        for round in range(num_rounds):\n",
    "            print(\"Cluster: \", cluster_number, \" - Building: \", building_index, \" - round: \", round)\n",
    "            \n",
    "            #0. Reset global step\n",
    "            tf.compat.v1.reset_default_graph()\n",
    "            global_step = tf.compat.v1.train.get_or_create_global_step()\n",
    "\n",
    "            #1. Initalize local agent\n",
    "            tf_ppo_agent, eval_policy, collect_policy = initialize_ppo_agent(\n",
    "                observation_spec = observation_spec, action_spec = action_spec,\n",
    "                global_step = global_step, environments = environments,\n",
    "                )\n",
    "            \n",
    "            #2. Set global weights of this training round to agent (loads the weights of last training)\n",
    "            model_dir = os.path.join(os.getcwd(), f\"models/ppo/cluster_{cluster_number}/FLround{best_federated_round}_c{num_clusters}_AvgAgg\")\n",
    "            tf_agent = set_weights_to_ppo_agent(tf_ppo_agent, model_dir)\n",
    "\n",
    "            #3. Prepare training pipeline: Setup iterator, replay buffer, driver\n",
    "            iterator, collect_driver, time_step, policy_state = setup_rl_training_pipeline(\n",
    "                tf_ppo_agent, environments[\"train\"][f\"building_{building_index}\"], replay_buffer_capacity,\n",
    "                collect_policy, initial_collect_steps, collect_steps_per_iteration, batch_size\n",
    "                )\n",
    "            \n",
    "            #4. Setup wandb logging\n",
    "            artifact = initialize_wandb_logging(name=f\"Exp_building{building_index}_rd{round}\", num_iterations=num_iterations)\n",
    "            \n",
    "            #5. Train, evaluate agent and store weights\n",
    "            result_df, metrics = agent_training_and_evaluation(global_step, num_test_iterations, collect_driver, \n",
    "                time_step, policy_state, iterator, tf_ppo_agent, eval_policy, building_index, result_df, eval_interval, environments)\n",
    "            \n",
    "            #6. End and log wandb\n",
    "            end_and_log_wandb(metrics, artifact)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
