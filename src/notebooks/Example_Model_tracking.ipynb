{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\rs1044\\Documents\\GitHub\\Federated-Reinforcement-Learning-for-Battery-Charging\\.venv\\lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Imports\n",
    "import pandas as pd\n",
    "import os\n",
    "import tensorflow as tf\n",
    "from keras import backend as K\n",
    "\n",
    "import sys\n",
    "sys.path.append(\"../\")\n",
    "from utils.modelgenerator import *\n",
    "from utils.modelhandler import *\n",
    "from utils.datahandler import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mjonas-sievers\u001b[0m (\u001b[33mipe\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import wandb\n",
    "from wandb.keras import WandbCallback\n",
    "wandb.login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>User11</th>\n",
       "      <th>temp</th>\n",
       "      <th>rhum</th>\n",
       "      <th>wspd</th>\n",
       "      <th>PC1</th>\n",
       "      <th>hour sin</th>\n",
       "      <th>hour cos</th>\n",
       "      <th>User11_lag_24hrs</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2012-07-08 00:00:00</th>\n",
       "      <td>0.312</td>\n",
       "      <td>9.8</td>\n",
       "      <td>85.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-2.453691</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-07-08 01:00:00</th>\n",
       "      <td>0.263</td>\n",
       "      <td>9.8</td>\n",
       "      <td>85.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-2.453691</td>\n",
       "      <td>0.258819</td>\n",
       "      <td>0.965926</td>\n",
       "      <td>0.316</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-07-08 02:00:00</th>\n",
       "      <td>0.257</td>\n",
       "      <td>9.8</td>\n",
       "      <td>85.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-2.453691</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.866025</td>\n",
       "      <td>0.356</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     User11  temp  rhum  wspd       PC1  hour sin  hour cos  \\\n",
       "Date                                                                          \n",
       "2012-07-08 00:00:00   0.312   9.8  85.0   0.0 -2.453691  0.000000  1.000000   \n",
       "2012-07-08 01:00:00   0.263   9.8  85.0   0.0 -2.453691  0.258819  0.965926   \n",
       "2012-07-08 02:00:00   0.257   9.8  85.0   0.0 -2.453691  0.500000  0.866025   \n",
       "\n",
       "                     User11_lag_24hrs  \n",
       "Date                                   \n",
       "2012-07-08 00:00:00             0.667  \n",
       "2012-07-08 01:00:00             0.316  \n",
       "2012-07-08 02:00:00             0.356  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Get data \n",
    "cwd = os.path.normpath(os.path.dirname(os.path.dirname(os.getcwd())))\n",
    "df = pd.read_csv(cwd+'/data/df_with_final_features.csv', index_col='Date') #df = pd.read_csv('user5.csv')\n",
    "df.index = pd.to_datetime(df.index)\n",
    "#df = df[['User5', 'temp', 'rhum']]\n",
    "df.fillna(0, inplace=True)\n",
    "\n",
    "#Select only 3 User for testing\n",
    "df_user10 = df[['User10', 'temp', 'rhum', 'wspd', 'PC1', 'hour sin', 'hour cos', 'User10_lag_24hrs']]\n",
    "df_user11 = df[['User11', 'temp', 'rhum', 'wspd', 'PC1', 'hour sin', 'hour cos', 'User11_lag_24hrs']]\n",
    "df_user12 = df[['User12', 'temp', 'rhum', 'wspd', 'PC1', 'hour sin', 'hour cos', 'User12_lag_24hrs']]\n",
    "df_array = [df_user10, df_user11, df_user12]\n",
    "df_array[1].head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Train, Validation and Test datasets\n",
    "sequence_length = 25\n",
    "batch_size = 16\n",
    "num_features = df_array[0].shape[1]\n",
    "\n",
    "dh = Datahandler()\n",
    "\n",
    "X_train, y_train, X_val, y_val, X_test, y_test = {}, {}, {}, {}, {}, {}\n",
    "\n",
    "#Create Train, Validation and Test datasets\n",
    "for idx, df in enumerate(df_array):\n",
    "    n = len(df)\n",
    "    train_df = df[0:int(n*0.7)]\n",
    "    val_df = df[int(n*0.7):int(n*0.9)]\n",
    "    test_df = df[int(n*0.9):]\n",
    "\n",
    "    # Min max sclaing\n",
    "    train_df = dh.min_max_scaling(train_df)\n",
    "    val_df = dh.min_max_scaling(val_df)\n",
    "    test_df = dh.min_max_scaling(test_df)\n",
    "\n",
    "    # Sequencing\n",
    "    train_sequences = dh.create_sequences(train_df, sequence_length)\n",
    "    val_sequences = dh.create_sequences(val_df, sequence_length)\n",
    "    test_sequences = dh.create_sequences(test_df, sequence_length)\n",
    "\n",
    "    #Split into feature and label\n",
    "    X_train[f'user1{idx}'], y_train[f'user1{idx}'] = dh.prepare_data(train_sequences, batch_size)\n",
    "    X_val[f'user1{idx}'], y_val[f'user1{idx}'] = dh.prepare_data(val_sequences, batch_size)\n",
    "    X_test[f'user1{idx}'], y_test[f'user1{idx}'] = dh.prepare_data(test_sequences, batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\Users\\rs1044\\Documents\\GitHub\\Federated-Reinforcement-Learning-for-Battery-Charging\\src\\notebooks\\wandb\\run-20231117_135823-o1upj2al</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/ipe/keras-integration/runs/o1upj2al' target=\"_blank\">quiet-snowflake-3</a></strong> to <a href='https://wandb.ai/ipe/keras-integration' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/ipe/keras-integration' target=\"_blank\">https://wandb.ai/ipe/keras-integration</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/ipe/keras-integration/runs/o1upj2al' target=\"_blank\">https://wandb.ai/ipe/keras-integration/runs/o1upj2al</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#General Hyperparameters\n",
    "# #All models\n",
    "horizon = 1\n",
    "max_epochs = 100\n",
    "m1 = ModelGenerator()\n",
    "mh = Modelhandler()\n",
    "\n",
    "loss = tf.keras.losses.MeanSquaredError()\n",
    "metrics=[\n",
    "    tf.keras.metrics.RootMeanSquaredError(), \n",
    "    tf.keras.metrics.MeanAbsolutePercentageError(),\n",
    "    tf.keras.metrics.MeanAbsoluteError(),\n",
    "]\n",
    "\n",
    "# Initialize wandb\n",
    "run = wandb.init(project='keras-integration',\n",
    "                 config={\n",
    "                     \"learning_rate\": 0.005,\n",
    "                     \"epochs\": max_epochs,\n",
    "                     \"batch_size\": batch_size,\n",
    "                     \"loss_function\": \"tf.keras.losses.MeanSquaredError()\",\n",
    "                     \"architecture\": \"Dense\",\n",
    "                     \"dataset\": \"Load\"\n",
    "                 })\n",
    "config = wandb.config  # We'll use this to configure our model\n",
    "\n",
    "early_stopping = tf.keras.callbacks.EarlyStopping(monitor='val_loss',patience=10,mode='min')\n",
    "timing_callback = TimingCallback()\n",
    "custom_callback = CustomCallback()\n",
    "callbacks=[early_stopping, timing_callback, custom_callback, WandbCallback()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.keras.backend.clear_session()\n",
    "dense_results = pd.DataFrame(columns=['architecture', 'Loss@User10','std@User10', 'Loss@User11','std@User11', 'Loss@User12','std@User12'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User:  0\n"
     ]
    },
    {
     "ename": "Error",
     "evalue": "wandb.watch only works with pytorch, couldn't import torch.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mError\u001b[0m                                     Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\rs1044\\Documents\\GitHub\\Federated-Reinforcement-Learning-for-Battery-Charging\\src\\notebooks\\Example_Model_tracking.ipynb Cell 7\u001b[0m line \u001b[0;36m2\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/rs1044/Documents/GitHub/Federated-Reinforcement-Learning-for-Battery-Charging/src/notebooks/Example_Model_tracking.ipynb#X20sZmlsZQ%3D%3D?line=16'>17</a>\u001b[0m \u001b[39mfor\u001b[39;00m \u001b[39mround\u001b[39m \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39m3\u001b[39m):\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/rs1044/Documents/GitHub/Federated-Reinforcement-Learning-for-Battery-Charging/src/notebooks/Example_Model_tracking.ipynb#X20sZmlsZQ%3D%3D?line=17'>18</a>\u001b[0m     \u001b[39m#print(\"Round: \", round)\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/rs1044/Documents/GitHub/Federated-Reinforcement-Learning-for-Battery-Charging/src/notebooks/Example_Model_tracking.ipynb#X20sZmlsZQ%3D%3D?line=18'>19</a>\u001b[0m     dense_model \u001b[39m=\u001b[39m m1\u001b[39m.\u001b[39mbuild_dense_model(X_train[\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39muser1\u001b[39m\u001b[39m{\u001b[39;00midx\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m], horizon, num_layers\u001b[39m=\u001b[39mdense_layers, units\u001b[39m=\u001b[39mdense_units, batch_size\u001b[39m=\u001b[39mconfig\u001b[39m.\u001b[39mbatch_size)\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/rs1044/Documents/GitHub/Federated-Reinforcement-Learning-for-Battery-Charging/src/notebooks/Example_Model_tracking.ipynb#X20sZmlsZQ%3D%3D?line=19'>20</a>\u001b[0m     wandb\u001b[39m.\u001b[39;49mwatch(dense_model)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/rs1044/Documents/GitHub/Federated-Reinforcement-Learning-for-Battery-Charging/src/notebooks/Example_Model_tracking.ipynb#X20sZmlsZQ%3D%3D?line=20'>21</a>\u001b[0m     dense_histroy, dense_user_results \u001b[39m=\u001b[39m mh\u001b[39m.\u001b[39mcompile_fit_evaluate_model(\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/rs1044/Documents/GitHub/Federated-Reinforcement-Learning-for-Battery-Charging/src/notebooks/Example_Model_tracking.ipynb#X20sZmlsZQ%3D%3D?line=21'>22</a>\u001b[0m         model\u001b[39m=\u001b[39mdense_model, \n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/rs1044/Documents/GitHub/Federated-Reinforcement-Learning-for-Battery-Charging/src/notebooks/Example_Model_tracking.ipynb#X20sZmlsZQ%3D%3D?line=22'>23</a>\u001b[0m         loss\u001b[39m=\u001b[39mloss, \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/rs1044/Documents/GitHub/Federated-Reinforcement-Learning-for-Battery-Charging/src/notebooks/Example_Model_tracking.ipynb#X20sZmlsZQ%3D%3D?line=35'>36</a>\u001b[0m         optimizer\u001b[39m=\u001b[39mtf\u001b[39m.\u001b[39mkeras\u001b[39m.\u001b[39moptimizers\u001b[39m.\u001b[39mAdam(learning_rate\u001b[39m=\u001b[39m\u001b[39m0.001\u001b[39m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/rs1044/Documents/GitHub/Federated-Reinforcement-Learning-for-Battery-Charging/src/notebooks/Example_Model_tracking.ipynb#X20sZmlsZQ%3D%3D?line=36'>37</a>\u001b[0m     )\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/rs1044/Documents/GitHub/Federated-Reinforcement-Learning-for-Battery-Charging/src/notebooks/Example_Model_tracking.ipynb#X20sZmlsZQ%3D%3D?line=37'>38</a>\u001b[0m     \u001b[39m# Add the 'architecture' column from dense_user_results to dense_results\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\rs1044\\Documents\\GitHub\\Federated-Reinforcement-Learning-for-Battery-Charging\\.venv\\lib\\site-packages\\wandb\\sdk\\wandb_watch.py:65\u001b[0m, in \u001b[0;36mwatch\u001b[1;34m(models, criterion, log, log_freq, idx, log_graph)\u001b[0m\n\u001b[0;32m     62\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(models, (\u001b[39mtuple\u001b[39m, \u001b[39mlist\u001b[39m)):\n\u001b[0;32m     63\u001b[0m     models \u001b[39m=\u001b[39m (models,)\n\u001b[1;32m---> 65\u001b[0m torch \u001b[39m=\u001b[39m wandb\u001b[39m.\u001b[39;49mutil\u001b[39m.\u001b[39;49mget_module(\n\u001b[0;32m     66\u001b[0m     \u001b[39m\"\u001b[39;49m\u001b[39mtorch\u001b[39;49m\u001b[39m\"\u001b[39;49m, required\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mwandb.watch only works with pytorch, couldn\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mt import torch.\u001b[39;49m\u001b[39m\"\u001b[39;49m\n\u001b[0;32m     67\u001b[0m )\n\u001b[0;32m     69\u001b[0m \u001b[39mfor\u001b[39;00m model \u001b[39min\u001b[39;00m models:\n\u001b[0;32m     70\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(model, torch\u001b[39m.\u001b[39mnn\u001b[39m.\u001b[39mModule):\n",
      "File \u001b[1;32mc:\\Users\\rs1044\\Documents\\GitHub\\Federated-Reinforcement-Learning-for-Battery-Charging\\.venv\\lib\\site-packages\\wandb\\util.py:269\u001b[0m, in \u001b[0;36mget_module\u001b[1;34m(name, required, lazy)\u001b[0m\n\u001b[0;32m    267\u001b[0m             logger\u001b[39m.\u001b[39mexception(msg)\n\u001b[0;32m    268\u001b[0m \u001b[39mif\u001b[39;00m required \u001b[39mand\u001b[39;00m name \u001b[39min\u001b[39;00m _not_importable:\n\u001b[1;32m--> 269\u001b[0m     \u001b[39mraise\u001b[39;00m wandb\u001b[39m.\u001b[39mError(required)\n",
      "\u001b[1;31mError\u001b[0m: wandb.watch only works with pytorch, couldn't import torch."
     ]
    }
   ],
   "source": [
    "#dense_architectures to test: \n",
    "\n",
    "#dense_architectures - tested: L1_U4, L2_U4, L3_U4, L4_U4, L5_U4, L1_U8, L2_U8, L3_U8, L4_U8, L5_U8, L1_U16, L2_U16, L3_U16, L4_U16, L5_U16, L1_U32\n",
    "#L2_U32, L3_U32, L1_U64, L2_U64, L1_U128, L2_U128, L1_U256, L2_U256, L1_U512, L2_U512\n",
    "\n",
    "#Dense Hyperparameter\n",
    "dense_architecture = \"L2_U512\"\n",
    "dense_layers = 2\n",
    "dense_units = 32\n",
    "\n",
    "#dense_results = pd.DataFrame(columns=['architecture', 'Loss@User10', 'Loss@User11', 'Loss@User12'])\n",
    "\n",
    "dense_all_results = pd.DataFrame(columns=[\"user\", \"architecture\", \"mse\"])\n",
    "#For each of the 3 user\n",
    "for idx in range(3):\n",
    "    print(\"User: \", idx)\n",
    "    for round in range(3):\n",
    "        #print(\"Round: \", round)\n",
    "        dense_model = m1.build_dense_model(X_train[f'user1{idx}'], horizon, num_layers=dense_layers, units=dense_units, batch_size=config.batch_size)\n",
    "        wandb.watch(dense_model)\n",
    "        dense_histroy, dense_user_results = mh.compile_fit_evaluate_model(\n",
    "            model=dense_model, \n",
    "            loss=loss, \n",
    "            metrics=metrics, \n",
    "            X_train=X_train[f'user1{idx}'],\n",
    "            y_train = y_train[f'user1{idx}'], \n",
    "            max_epochs = max_epochs, \n",
    "            batch_size=batch_size, \n",
    "            X_val=X_val[f'user1{idx}'], \n",
    "            y_val=y_val[f'user1{idx}'], \n",
    "            X_test=X_test[f'user1{idx}'], \n",
    "            y_test=y_test[f'user1{idx}'], \n",
    "            callbacks=callbacks, \n",
    "            user=f'user1{idx}', \n",
    "            hyper=dense_architecture,\n",
    "            optimizer=tf.keras.optimizers.Adam(learning_rate=0.001)\n",
    "        )\n",
    "        # Add the 'architecture' column from dense_user_results to dense_results\n",
    "        dense_all_results = pd.merge(dense_all_results, dense_user_results, how='outer')   \n",
    "\n",
    "new_row = {\n",
    "    'architecture': dense_all_results[\"architecture\"][0],\n",
    "    'Loss@User10': dense_all_results[dense_all_results[\"user\"]==\"user10\"][\"mse\"].mean(),\n",
    "    'std@User10' : dense_all_results[dense_all_results[\"user\"]==\"user10\"][\"mse\"].std(),\n",
    "    'Loss@User11': dense_all_results[dense_all_results[\"user\"]==\"user11\"][\"mse\"].mean(),\n",
    "    'std@User11' : dense_all_results[dense_all_results[\"user\"]==\"user11\"][\"mse\"].std(),\n",
    "    'Loss@User12': dense_all_results[dense_all_results[\"user\"]==\"user12\"][\"mse\"].mean(),\n",
    "    'std@User12' : dense_all_results[dense_all_results[\"user\"]==\"user12\"][\"mse\"].std(),\n",
    "}\n",
    "dense_results.loc[len(dense_results)] = new_row\n",
    "print(dense_results)\n",
    "run.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm_results = pd.DataFrame(columns=['architecture', 'Loss@User10','std@User10', 'Loss@User11','std@User11', 'Loss@User12','std@User12'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User:  0\n",
      "Round:  0\n",
      "Round:  1\n",
      "Round:  2\n",
      "User:  1\n",
      "Round:  0\n",
      "Round:  1\n",
      "Round:  2\n",
      "User:  2\n",
      "Round:  0\n",
      "Round:  1\n",
      "Round:  2\n",
      "  architecture  Loss@User10  std@User10  Loss@User11  std@User11  Loss@User12  \\\n",
      "0    Bi_L2_U20     0.019668    0.003406     0.017234    0.001019      0.01073   \n",
      "\n",
      "   std@User12  \n",
      "0    0.001039  \n"
     ]
    }
   ],
   "source": [
    "#LSTM Hyperparameter\n",
    "lstm_architecture = \"Bi_L2_U20\"\n",
    "lstm_layers = 2\n",
    "lstm_units = 8\n",
    "\n",
    "#lstm_results = pd.DataFrame(columns=['architecture', 'Loss@User10', 'Loss@User11', 'Loss@User12'])\n",
    "\n",
    "lstm_all_results = pd.DataFrame(columns=[\"user\", \"architecture\", \"mse\"])\n",
    "#For each of the 3 user\n",
    "for idx in range(3):\n",
    "    print(\"User: \", idx)\n",
    "    for round in range(3):\n",
    "        print(\"Round: \", round)\n",
    "        #lstm_model = m1.build_lstm_model(X_train[f'user1{idx}'], horizon, lstm_layers, lstm_units, batch_size)\n",
    "        lstm_model = m1.build_bilstm_model(X_train[f'user1{idx}'], horizon, lstm_layers, lstm_units, batch_size)\n",
    "        lstm_histroy, lstm_user_results = mh.compile_fit_evaluate_model(\n",
    "            model=lstm_model, \n",
    "            loss=loss, \n",
    "            metrics=metrics, \n",
    "            X_train=X_train[f'user1{idx}'],\n",
    "            y_train = y_train[f'user1{idx}'], \n",
    "            max_epochs = max_epochs, \n",
    "            batch_size=batch_size, \n",
    "            X_val=X_val[f'user1{idx}'], \n",
    "            y_val=y_val[f'user1{idx}'], \n",
    "            X_test=X_test[f'user1{idx}'], \n",
    "            y_test=y_test[f'user1{idx}'], \n",
    "            callbacks=callbacks, \n",
    "            user=f'user1{idx}', \n",
    "            hyper=lstm_architecture,\n",
    "            optimizer=tf.keras.optimizers.Adam(learning_rate=0.001)\n",
    "        )\n",
    "        # Add the 'architecture' column from lstm_user_results to lstm_results\n",
    "        lstm_all_results = pd.merge(lstm_all_results, lstm_user_results, how='outer')   \n",
    "\n",
    "new_row = {\n",
    "    'architecture': lstm_all_results[\"architecture\"][0],\n",
    "    'Loss@User10': lstm_all_results[lstm_all_results[\"user\"]==\"user10\"][\"mse\"].mean(),\n",
    "    'std@User10' : lstm_all_results[lstm_all_results[\"user\"]==\"user10\"][\"mse\"].std(),\n",
    "    'Loss@User11': lstm_all_results[lstm_all_results[\"user\"]==\"user11\"][\"mse\"].mean(),\n",
    "    'std@User11' : lstm_all_results[lstm_all_results[\"user\"]==\"user11\"][\"mse\"].std(),\n",
    "    'Loss@User12': lstm_all_results[lstm_all_results[\"user\"]==\"user12\"][\"mse\"].mean(),\n",
    "    'std@User12' : lstm_all_results[lstm_all_results[\"user\"]==\"user12\"][\"mse\"].std(),\n",
    "}\n",
    "lstm_results.loc[len(lstm_results)] = new_row\n",
    "print(lstm_results)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
