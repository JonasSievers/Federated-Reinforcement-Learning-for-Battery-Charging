{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\rs1044\\Documents\\GitHub\\Federated-Reinforcement-Learning-for-Battery-Charging\\.venv\\lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\rs1044\\AppData\\Local\\Temp\\ipykernel_11556\\2749853428.py:18: The name tf.logging.set_verbosity is deprecated. Please use tf.compat.v1.logging.set_verbosity instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Imports\n",
    "\n",
    "import logging\n",
    "import os\n",
    "logging.getLogger(\"wandb\").setLevel(logging.ERROR)\n",
    "logging.getLogger('tensorflow').setLevel(logging.ERROR)\n",
    "os.environ['WANDB_SILENT'] = 'true'\n",
    "os.environ['WANDB_CONSOLE'] = 'off'\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "import tensorflow as tf\n",
    "tf.compat.v1.logging.set_verbosity(tf.compat.v1.logging.ERROR)\n",
    "from tf_agents.agents.ddpg import ddpg_agent\n",
    "from tf_agents.drivers import dynamic_step_driver\n",
    "from tf_agents.environments import tf_py_environment, py_environment, batched_py_environment\n",
    "from tf_agents.eval import metric_utils\n",
    "from tf_agents.metrics import tf_metrics\n",
    "from tf_agents.replay_buffers import tf_uniform_replay_buffer\n",
    "from tf_agents.utils import common\n",
    "import matplotlib.pyplot as plt\n",
    "import wandb\n",
    "\n",
    "import sys\n",
    "sys.path.insert(0, '..')\n",
    "from environments.EnergyManagementEnv import EnergyManagementEnv\n",
    "from utils.agentNetworks import ActorNetwork, CriticNetwork, CustomLayers\n",
    "import utils.dataloader as DL\n",
    "from utils.federatedLearningHandler import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Also possible: Attention score: Rank based, soft-max ohne normalization \n",
    "def calculate_mean_weights_with_noise(weights_list, noise_scale=0.1):\n",
    "    # Assuming weights_list is a list containing two elements, where each element\n",
    "    # is a list of numpy arrays representing the weights of an actor network\n",
    "    mean_weights = []\n",
    "\n",
    "    for weight_pair in zip(*weights_list):\n",
    "        print(weight_pair)\n",
    "        #1. Averaging\n",
    "        mean_weight = tf.math.reduce_mean(tf.convert_to_tensor(weight_pair), axis=0)\n",
    "        \n",
    "        #2. Adding noise\n",
    "        noise = tf.random.normal(shape=mean_weight.shape, mean=0.0, stddev=noise_scale)\n",
    "        noisy_mean_weight = mean_weight + noise\n",
    "\n",
    "        mean_weights.append(noisy_mean_weight)\n",
    "    return mean_weights\n",
    "\n",
    "\n",
    "def calculate_mean_weights_with_softmax_attention(weights_list, performance_metrics, noise_scale=0.3):\n",
    "    \n",
    "    # Check if weights_list only contains weights from one building\n",
    "    if len(weights_list) == 1:\n",
    "        # If so, simply return the weights with noise added\n",
    "        single_building_weights = weights_list[0]\n",
    "        noisy_single_building_weights = []\n",
    "        for weight in single_building_weights:\n",
    "            noise = tf.random.normal(shape=weight.shape, mean=0.0, stddev=noise_scale)\n",
    "            noisy_single_building_weights.append(weight + noise)\n",
    "        return noisy_single_building_weights\n",
    "    \n",
    "    mean_weights = []\n",
    "    #Claulate standardized attention scores\n",
    "    performance_metrics_tensor = tf.convert_to_tensor(performance_metrics, dtype=tf.float32)\n",
    "    standardized_metrics = (performance_metrics_tensor - tf.reduce_mean(performance_metrics_tensor)) / tf.math.reduce_std(performance_metrics_tensor)\n",
    "    attention_scores = tf.nn.softmax(standardized_metrics)\n",
    "\n",
    "    for weight_pair in zip(*weights_list):\n",
    "        \n",
    "        stacked_weights = tf.stack(weight_pair, axis=0)\n",
    "        weighted_mean_weight = tf.zeros_like(stacked_weights[0])\n",
    "\n",
    "        # Iterate through each model's weights and the corresponding attention score\n",
    "        for model_weights, attention_score in zip(stacked_weights, attention_scores):\n",
    "            \n",
    "            weighted_model_weights = model_weights * attention_score\n",
    "            \n",
    "            # Add noise to the weighted model weights\n",
    "            noise = tf.random.normal(shape=weighted_model_weights.shape, mean=0.0, stddev=noise_scale)\n",
    "            noisy_weighted_model_weights = weighted_model_weights + noise\n",
    "            \n",
    "            # Accumulate the weighted (and noised) weights\n",
    "            weighted_mean_weight += noisy_weighted_model_weights\n",
    "        \n",
    "        mean_weights.append(weighted_mean_weight)\n",
    "    \n",
    "    return mean_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def federated_aggregation(weights_list, performance_metrics, noise_scale=0.1):\n",
    "    mean_weights = []\n",
    "\n",
    "    for weight_pair in zip(*weights_list):\n",
    "        print(weight_pair)\n",
    "        #1. Averaging\n",
    "        mean_weight = tf.math.reduce_mean(tf.convert_to_tensor(weight_pair), axis=0)\n",
    "        \n",
    "        #2. Adding noise\n",
    "        noise = tf.random.normal(shape=mean_weight.shape, mean=0.0, stddev=noise_scale)\n",
    "        noisy_mean_weight = mean_weight + noise\n",
    "\n",
    "        mean_weights.append(noisy_mean_weight)\n",
    "    return mean_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch size:  1\n",
      "State Space: 6, Action Space: 1\n",
      "Upper bound: 2.3\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>load_1</th>\n",
       "      <th>pv_1</th>\n",
       "      <th>price</th>\n",
       "      <th>fuelmix</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.149</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.05704</td>\n",
       "      <td>0.530991</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   load_1  pv_1    price   fuelmix\n",
       "0   1.149   0.0  0.05704  0.530991"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_buildings = 30\n",
    "energy_data = pd.read_csv(\"../../data/3final_data/Final_Energy_dataset.csv\", header=0)\n",
    "energy_data.set_index('Date', inplace=True)\n",
    "energy_data.fillna(0, inplace=True)\n",
    "\n",
    "dataset = {\"train\": {}, \"eval\": {}, \"test\": {}}\n",
    "environments = {\"train\": {}, \"eval\": {}, \"test\": {}}\n",
    "for idx in range(num_buildings):\n",
    "    user_data = energy_data[[f'load_{idx+1}', f'pv_{idx+1}', 'price', 'fuelmix']]\n",
    "    \n",
    "    dataset[\"train\"][f\"building_{idx+1}\"] = user_data[0:17520].set_index(pd.RangeIndex(0,17520))\n",
    "    dataset[\"eval\"][f\"building_{idx+1}\"] = user_data[17520:35088].set_index(pd.RangeIndex(0,17568))\n",
    "    dataset[\"test\"][f\"building_{idx+1}\"] = user_data[35088:52608].set_index(pd.RangeIndex(0,17520))\n",
    "\n",
    "    environments[\"train\"][f\"building_{idx+1}\"] = tf_py_environment.TFPyEnvironment(EnergyManagementEnv(init_charge=0.0, data=dataset[\"train\"][f\"building_{idx+1}\"]))\n",
    "    environments[\"eval\"][f\"building_{idx+1}\"] = tf_py_environment.TFPyEnvironment(EnergyManagementEnv(init_charge=0.0, data=dataset[\"eval\"][f\"building_{idx+1}\"]))\n",
    "    environments[\"test\"][f\"building_{idx+1}\"] = tf_py_environment.TFPyEnvironment(EnergyManagementEnv(init_charge=0.0, data=dataset[\"test\"][f\"building_{idx+1}\"], logging=True))\n",
    "\n",
    "print(\"Batch size: \", environments[\"train\"][f\"building_1\"].batch_size)\n",
    "print(\"State Space: {}, Action Space: {}\".format(environments[\"train\"][f\"building_1\"].observation_spec().shape[0], environments[\"train\"][f\"building_1\"].action_spec().shape[0])) #SoE, price, price forecast 1-6\n",
    "print(\"Upper bound: {}\".format(round(environments[\"train\"][f\"building_1\"].action_spec().maximum.item(), 3)))\n",
    "dataset[\"test\"][f\"building_1\"].head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "federated_rounds = 5\n",
    "num_clusters = 18\n",
    "# 2, 6, 10, 12, 14, 16, 18"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: array([7], dtype=int64),\n",
       " 1: array([17], dtype=int64),\n",
       " 2: array([13, 19, 20], dtype=int64),\n",
       " 3: array([18], dtype=int64),\n",
       " 4: array([ 9, 30], dtype=int64),\n",
       " 5: array([1], dtype=int64),\n",
       " 6: array([6], dtype=int64),\n",
       " 7: array([11], dtype=int64),\n",
       " 8: array([23, 24, 26, 28, 29], dtype=int64),\n",
       " 9: array([2], dtype=int64),\n",
       " 10: array([8], dtype=int64),\n",
       " 11: array([21], dtype=int64),\n",
       " 12: array([ 3,  4, 14, 15, 22], dtype=int64),\n",
       " 13: array([16], dtype=int64),\n",
       " 14: array([10], dtype=int64),\n",
       " 15: array([27], dtype=int64),\n",
       " 16: array([25], dtype=int64),\n",
       " 17: array([ 5, 12], dtype=int64)}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = np.loadtxt(f'../../data/3final_data/Clusters_KMeans_dtw_c{num_clusters}.csv', delimiter=',').astype(int)\n",
    "\n",
    "cluster_buildings = {i: [] for i in range(num_clusters)}\n",
    "\n",
    "# Iterate through each cluster\n",
    "for cluster_number in range(num_clusters):\n",
    "    buildings_in_cluster = np.where(y == cluster_number)[0] +1\n",
    "    cluster_buildings[cluster_number] = buildings_in_cluster\n",
    "cluster_buildings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup Agent networks\n",
    "batch_size = 128\n",
    "replay_buffer_capacity = 20000 #-> only <18.000 samples per dataset\n",
    "initial_collect_steps = 2000\n",
    "collect_steps_per_iteration = 20 \n",
    "num_iterations = 10000 #10000\n",
    "eval_interval = 9500 #3000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "global_weights = {\"actor_net\": {}, \"critic_net\": {}, \"target_actor_network\": {}, \"target_critic_network\": {}}\n",
    "\n",
    "#Initalize a global model for each Cluster of similar buildings\n",
    "for cluster in range(num_clusters):\n",
    "        # 1. Build global agent per cluster\n",
    "        tf.compat.v1.reset_default_graph()\n",
    "        global_step = tf.compat.v1.train.get_or_create_global_step()\n",
    "        first_building_in_cluster = cluster_buildings[cluster][0]\n",
    "\n",
    "        global_tf_agent, global_eval_policy, global_collect_policy = get_ddpg_agent(\n",
    "                observation_spec = environments[\"train\"][f\"building_{first_building_in_cluster}\"].observation_spec(),\n",
    "                action_spec = environments[\"train\"][f\"building_{first_building_in_cluster}\"].action_spec(),\n",
    "                custom_layers = [CustomLayers.get_dense_layers(layers=1, units=32)],\n",
    "                global_step = global_step,\n",
    "                environments = environments,\n",
    "                )\n",
    "\n",
    "        # 2. Initially store weights\n",
    "        global_weights[\"actor_net\"][cluster] = global_tf_agent._actor_network.get_weights()\n",
    "        global_weights[\"critic_net\"][cluster] = global_tf_agent._critic_network.get_weights()\n",
    "        global_weights[\"target_actor_network\"][cluster] = global_tf_agent._target_actor_network.get_weights()\n",
    "        global_weights[\"target_critic_network\"][cluster] = global_tf_agent._target_critic_network.get_weights()\n",
    "\n",
    "        model_dir = os.path.join(os.getcwd(), f\"models/cluster_{cluster}/FLround{0}_c{num_clusters}_WAAwN\")\n",
    "        os.makedirs(model_dir, exist_ok=True)\n",
    "\n",
    "        np.savez(os.path.join(model_dir, \"actor_network_weights.npz\"), *global_tf_agent._actor_network.get_weights())\n",
    "        np.savez(os.path.join(model_dir, \"critic_weights.npz\"), *global_tf_agent._critic_network.get_weights())\n",
    "        np.savez(os.path.join(model_dir, \"target_actor_weights.npz\"), *global_tf_agent._target_actor_network.get_weights())\n",
    "        np.savez(os.path.join(model_dir, \"target_critic_weights.npz\"), *global_tf_agent._target_critic_network.get_weights())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cluster 0: Buildings [7] Federated round ---------- 1 / 5\n",
      "Return:  4947.773\n",
      "Performance List:  [4947.773]\n",
      "Cluster 1: Buildings [17] Federated round ---------- 1 / 5\n",
      "Return:  4138.058\n",
      "Performance List:  [4138.058]\n",
      "Cluster 2: Buildings [13 19 20] Federated round ---------- 1 / 5\n",
      "Return:  4982.4443\n",
      "Return:  4877.625\n",
      "Return:  4795.5405\n",
      "Performance List:  [4982.4443, 4877.625, 4795.5405]\n",
      "Cluster 3: Buildings [18] Federated round ---------- 1 / 5\n",
      "Return:  4237.4927\n",
      "Performance List:  [4237.4927]\n",
      "Cluster 4: Buildings [ 9 30] Federated round ---------- 1 / 5\n",
      "Return:  4459.204\n",
      "Return:  4678.903\n",
      "Performance List:  [4459.204, 4678.903]\n",
      "Cluster 5: Buildings [1] Federated round ---------- 1 / 5\n",
      "Return:  5415.0923\n",
      "Performance List:  [5415.0923]\n",
      "Cluster 6: Buildings [6] Federated round ---------- 1 / 5\n",
      "Return:  4087.658\n",
      "Performance List:  [4087.658]\n",
      "Cluster 7: Buildings [11] Federated round ---------- 1 / 5\n",
      "Return:  4493.451\n",
      "Performance List:  [4493.451]\n",
      "Cluster 8: Buildings [23 24 26 28 29] Federated round ---------- 1 / 5\n",
      "Return:  4514.2656\n",
      "Return:  6515.3438\n",
      "Return:  4084.74\n",
      "Return:  4454.4897\n",
      "Return:  4553.824\n",
      "Performance List:  [4514.2656, 6515.3438, 4084.74, 4454.4897, 4553.824]\n",
      "Cluster 9: Buildings [2] Federated round ---------- 1 / 5\n",
      "Return:  4184.199\n",
      "Performance List:  [4184.199]\n",
      "Cluster 10: Buildings [8] Federated round ---------- 1 / 5\n",
      "Return:  3114.1062\n",
      "Performance List:  [3114.1062]\n",
      "Cluster 11: Buildings [21] Federated round ---------- 1 / 5\n",
      "Return:  3474.4587\n",
      "Performance List:  [3474.4587]\n",
      "Cluster 12: Buildings [ 3  4 14 15 22] Federated round ---------- 1 / 5\n",
      "Return:  4349.8687\n",
      "Return:  4381.4937\n",
      "Return:  4561.4507\n",
      "Return:  4521.667\n",
      "Return:  4451.918\n",
      "Performance List:  [4349.8687, 4381.4937, 4561.4507, 4521.667, 4451.918]\n",
      "Cluster 13: Buildings [16] Federated round ---------- 1 / 5\n",
      "Return:  4212.42\n",
      "Performance List:  [4212.42]\n",
      "Cluster 14: Buildings [10] Federated round ---------- 1 / 5\n",
      "Return:  4130.044\n",
      "Performance List:  [4130.044]\n",
      "Cluster 15: Buildings [27] Federated round ---------- 1 / 5\n",
      "Return:  4236.8994\n",
      "Performance List:  [4236.8994]\n",
      "Cluster 16: Buildings [25] Federated round ---------- 1 / 5\n",
      "Return:  4232.855\n",
      "Performance List:  [4232.855]\n",
      "Cluster 17: Buildings [ 5 12] Federated round ---------- 1 / 5\n",
      "Return:  4522.781\n",
      "Return:  4303.5513\n",
      "Performance List:  [4522.781, 4303.5513]\n",
      "Cluster 0: Buildings [7] Federated round ---------- 2 / 5\n",
      "Return:  -191534.31\n",
      "Performance List:  [-191534.31]\n",
      "Cluster 1: Buildings [17] Federated round ---------- 2 / 5\n",
      "Return:  4208.626\n",
      "Performance List:  [4208.626]\n",
      "Cluster 2: Buildings [13 19 20] Federated round ---------- 2 / 5\n",
      "Return:  4845.9717\n",
      "Return:  -191609.48\n",
      "Return:  -191628.88\n",
      "Performance List:  [4845.9717, -191609.48, -191628.88]\n",
      "Cluster 3: Buildings [18] Federated round ---------- 2 / 5\n",
      "Return:  4108.4346\n",
      "Performance List:  [4108.4346]\n",
      "Cluster 4: Buildings [ 9 30] Federated round ---------- 2 / 5\n",
      "Return:  -192029.84\n",
      "Return:  -191802.06\n",
      "Performance List:  [-192029.84, -191802.06]\n",
      "Cluster 5: Buildings [1] Federated round ---------- 2 / 5\n",
      "Return:  5398.102\n",
      "Performance List:  [5398.102]\n",
      "Cluster 6: Buildings [6] Federated round ---------- 2 / 5\n",
      "Return:  4044.082\n",
      "Performance List:  [4044.082]\n",
      "Cluster 7: Buildings [11] Federated round ---------- 2 / 5\n",
      "Return:  -192000.88\n",
      "Performance List:  [-192000.88]\n",
      "Cluster 8: Buildings [23 24 26 28 29] Federated round ---------- 2 / 5\n",
      "Return:  -191961.45\n",
      "Return:  -189979.22\n",
      "Return:  3939.6174\n",
      "Return:  4153.1045\n",
      "Return:  -191937.78\n",
      "Performance List:  [-191961.45, -189979.22, 3939.6174, 4153.1045, -191937.78]\n",
      "Cluster 9: Buildings [2] Federated round ---------- 2 / 5\n",
      "Return:  4119.252\n",
      "Performance List:  [4119.252]\n",
      "Cluster 10: Buildings [8] Federated round ---------- 2 / 5\n",
      "Return:  3119.8782\n",
      "Performance List:  [3119.8782]\n",
      "Cluster 11: Buildings [21] Federated round ---------- 2 / 5\n",
      "Return:  3397.895\n",
      "Performance List:  [3397.895]\n",
      "Cluster 12: Buildings [ 3  4 14 15 22] Federated round ---------- 2 / 5\n",
      "Return:  -191775.86\n",
      "Return:  -192080.39\n",
      "Return:  -191618.3\n",
      "Return:  -191864.6\n",
      "Return:  -191983.17\n",
      "Performance List:  [-191775.86, -192080.39, -191618.3, -191864.6, -191983.17]\n",
      "Cluster 13: Buildings [16] Federated round ---------- 2 / 5\n",
      "Return:  4177.579\n",
      "Performance List:  [4177.579]\n",
      "Cluster 14: Buildings [10] Federated round ---------- 2 / 5\n",
      "Return:  374.93427\n",
      "Performance List:  [374.93427]\n",
      "Cluster 15: Buildings [27] Federated round ---------- 2 / 5\n",
      "Return:  4164.407\n",
      "Performance List:  [4164.407]\n",
      "Cluster 16: Buildings [25] Federated round ---------- 2 / 5\n",
      "Return:  4205.6357\n",
      "Performance List:  [4205.6357]\n",
      "Cluster 17: Buildings [ 5 12] Federated round ---------- 2 / 5\n",
      "Return:  4394.8286\n",
      "Return:  3719.2598\n",
      "Performance List:  [4394.8286, 3719.2598]\n",
      "Cluster 0: Buildings [7] Federated round ---------- 3 / 5\n",
      "Return:  -191534.31\n",
      "Performance List:  [-191534.31]\n",
      "Cluster 1: Buildings [17] Federated round ---------- 3 / 5\n",
      "Return:  -192189.3\n",
      "Performance List:  [-192189.3]\n",
      "Cluster 2: Buildings [13 19 20] Federated round ---------- 3 / 5\n",
      "Return:  -191509.77\n",
      "Return:  -191609.48\n",
      "Return:  -191610.47\n",
      "Performance List:  [-191509.77, -191609.48, -191610.47]\n",
      "Cluster 3: Buildings [18] Federated round ---------- 3 / 5\n",
      "Return:  4216.2656\n",
      "Performance List:  [4216.2656]\n",
      "Cluster 4: Buildings [ 9 30] Federated round ---------- 3 / 5\n",
      "Return:  -192029.84\n",
      "Return:  -191802.06\n",
      "Performance List:  [-192029.84, -191802.06]\n",
      "Cluster 5: Buildings [1] Federated round ---------- 3 / 5\n",
      "Return:  -190996.95\n",
      "Performance List:  [-190996.95]\n",
      "Cluster 6: Buildings [6] Federated round ---------- 3 / 5\n",
      "Return:  3708.2659\n",
      "Performance List:  [3708.2659]\n",
      "Cluster 7: Buildings [11] Federated round ---------- 3 / 5\n",
      "Return:  -192000.88\n",
      "Performance List:  [-192000.88]\n",
      "Cluster 8: Buildings [23 24 26 28 29] Federated round ---------- 3 / 5\n",
      "Return:  -191961.45\n",
      "Return:  -189979.22\n",
      "Return:  -192403.7\n",
      "Return:  -191900.92\n",
      "Return:  -191919.4\n",
      "Performance List:  [-191961.45, -189979.22, -192403.7, -191900.92, -191919.4]\n",
      "Cluster 9: Buildings [2] Federated round ---------- 3 / 5\n",
      "Return:  4173.278\n",
      "Performance List:  [4173.278]\n",
      "Cluster 10: Buildings [8] Federated round ---------- 3 / 5\n",
      "Return:  2757.0078\n",
      "Performance List:  [2757.0078]\n",
      "Cluster 11: Buildings [21] Federated round ---------- 3 / 5\n",
      "Return:  3281.9387\n",
      "Performance List:  [3281.9387]\n",
      "Cluster 12: Buildings [ 3  4 14 15 22] Federated round ---------- 3 / 5\n",
      "Return:  -191716.61\n",
      "Return:  -192021.17\n",
      "Return:  -191618.3\n",
      "Return:  -191864.6\n",
      "Return:  -191990.78\n",
      "Performance List:  [-191716.61, -192021.17, -191618.3, -191864.6, -191990.78]\n",
      "Cluster 13: Buildings [16] Federated round ---------- 3 / 5\n",
      "Return:  -192186.72\n",
      "Performance List:  [-192186.72]\n",
      "Cluster 14: Buildings [10] Federated round ---------- 3 / 5\n",
      "Return:  4123.3516\n",
      "Performance List:  [4123.3516]\n",
      "Cluster 15: Buildings [27] Federated round ---------- 3 / 5\n",
      "Return:  -192180.08\n",
      "Performance List:  [-192180.08]\n",
      "Cluster 16: Buildings [25] Federated round ---------- 3 / 5\n",
      "Return:  -192159.4\n",
      "Performance List:  [-192159.4]\n",
      "Cluster 17: Buildings [ 5 12] Federated round ---------- 3 / 5\n",
      "Return:  -191895.81\n",
      "Return:  -192189.8\n",
      "Performance List:  [-191895.81, -192189.8]\n",
      "Cluster 0: Buildings [7] Federated round ---------- 4 / 5\n",
      "Return:  -191534.31\n",
      "Performance List:  [-191534.31]\n",
      "Cluster 1: Buildings [17] Federated round ---------- 4 / 5\n",
      "Return:  -192189.3\n",
      "Performance List:  [-192189.3]\n",
      "Cluster 2: Buildings [13 19 20] Federated round ---------- 4 / 5\n",
      "Return:  -191509.77\n",
      "Return:  -191609.48\n",
      "Return:  -191688.12\n",
      "Performance List:  [-191509.77, -191609.48, -191688.12]\n",
      "Cluster 3: Buildings [18] Federated round ---------- 4 / 5\n",
      "Return:  -192254.9\n",
      "Performance List:  [-192254.9]\n",
      "Cluster 4: Buildings [ 9 30] Federated round ---------- 4 / 5\n",
      "Return:  -192029.84\n",
      "Return:  -191802.06\n",
      "Performance List:  [-192029.84, -191802.06]\n",
      "Cluster 5: Buildings [1] Federated round ---------- 4 / 5\n",
      "Return:  -190996.95\n",
      "Performance List:  [-190996.95]\n",
      "Cluster 6: Buildings [6] Federated round ---------- 4 / 5\n",
      "Return:  -192367.38\n",
      "Performance List:  [-192367.38]\n",
      "Cluster 7: Buildings [11] Federated round ---------- 4 / 5\n",
      "Return:  -191941.67\n",
      "Performance List:  [-191941.67]\n",
      "Cluster 8: Buildings [23 24 26 28 29] Federated round ---------- 4 / 5\n",
      "Return:  -191943.02\n",
      "Return:  -189979.22\n",
      "Return:  -192344.47\n",
      "Return:  -191941.72\n",
      "Return:  -191878.56\n",
      "Performance List:  [-191943.02, -189979.22, -192344.47, -191941.72, -191878.56]\n",
      "Cluster 9: Buildings [2] Federated round ---------- 4 / 5\n",
      "Return:  -192204.86\n",
      "Performance List:  [-192204.86]\n",
      "Cluster 10: Buildings [8] Federated round ---------- 4 / 5\n",
      "Return:  -193268.88\n",
      "Performance List:  [-193268.88]\n",
      "Cluster 11: Buildings [21] Federated round ---------- 4 / 5\n",
      "Return:  -192940.47\n",
      "Performance List:  [-192940.47]\n",
      "Cluster 12: Buildings [ 3  4 14 15 22] Federated round ---------- 4 / 5\n",
      "Return:  -191716.61\n",
      "Return:  -192080.39\n",
      "Return:  -191618.3\n",
      "Return:  -191805.38\n",
      "Return:  -191923.94\n",
      "Performance List:  [-191716.61, -192080.39, -191618.3, -191805.38, -191923.94]\n",
      "Cluster 13: Buildings [16] Federated round ---------- 4 / 5\n",
      "Return:  -192186.72\n",
      "Performance List:  [-192186.72]\n",
      "Cluster 14: Buildings [10] Federated round ---------- 4 / 5\n",
      "Return:  4142.392\n",
      "Performance List:  [4142.392]\n",
      "Cluster 15: Buildings [27] Federated round ---------- 4 / 5\n",
      "Return:  -192180.08\n",
      "Performance List:  [-192180.08]\n",
      "Cluster 16: Buildings [25] Federated round ---------- 4 / 5\n",
      "Return:  -192159.4\n",
      "Performance List:  [-192159.4]\n",
      "Cluster 17: Buildings [ 5 12] Federated round ---------- 4 / 5\n",
      "Return:  4501.7905\n",
      "Return:  4310.5757\n",
      "Performance List:  [4501.7905, 4310.5757]\n",
      "Cluster 0: Buildings [7] Federated round ---------- 5 / 5\n",
      "Return:  -191534.31\n",
      "Performance List:  [-191534.31]\n",
      "Cluster 1: Buildings [17] Federated round ---------- 5 / 5\n",
      "Return:  -192266.92\n",
      "Performance List:  [-192266.92]\n",
      "Cluster 2: Buildings [13 19 20] Federated round ---------- 5 / 5\n",
      "Return:  -191509.77\n",
      "Return:  -191609.48\n",
      "Return:  -191688.12\n",
      "Performance List:  [-191509.77, -191609.48, -191688.12]\n",
      "Cluster 3: Buildings [18] Federated round ---------- 5 / 5\n",
      "Return:  -192254.9\n",
      "Performance List:  [-192254.9]\n",
      "Cluster 4: Buildings [ 9 30] Federated round ---------- 5 / 5\n",
      "Return:  -192029.84\n",
      "Return:  -191802.06\n",
      "Performance List:  [-192029.84, -191802.06]\n",
      "Cluster 5: Buildings [1] Federated round ---------- 5 / 5\n",
      "Return:  -190996.95\n",
      "Performance List:  [-190996.95]\n",
      "Cluster 6: Buildings [6] Federated round ---------- 5 / 5\n",
      "Return:  -192367.38\n",
      "Performance List:  [-192367.38]\n",
      "Cluster 7: Buildings [11] Federated round ---------- 5 / 5\n",
      "Return:  -191941.67\n",
      "Performance List:  [-191941.67]\n",
      "Cluster 8: Buildings [23 24 26 28 29] Federated round ---------- 5 / 5\n",
      "Return:  -191961.45\n",
      "Return:  -189979.22\n",
      "Return:  -192403.7\n",
      "Return:  -191960.14\n",
      "Return:  -191937.78\n",
      "Performance List:  [-191961.45, -189979.22, -192403.7, -191960.14, -191937.78]\n",
      "Cluster 9: Buildings [2] Federated round ---------- 5 / 5\n",
      "Return:  -192223.23\n",
      "Performance List:  [-192223.23]\n",
      "Cluster 10: Buildings [8] Federated round ---------- 5 / 5\n",
      "Return:  -193268.88\n",
      "Performance List:  [-193268.88]\n",
      "Cluster 11: Buildings [21] Federated round ---------- 5 / 5\n",
      "Return:  -192940.47\n",
      "Performance List:  [-192940.47]\n",
      "Cluster 12: Buildings [ 3  4 14 15 22] Federated round ---------- 5 / 5\n",
      "Return:  -191775.86\n",
      "Return:  -192080.39\n",
      "Return:  -191559.08\n",
      "Return:  -191787.0\n",
      "Return:  -191923.94\n",
      "Performance List:  [-191775.86, -192080.39, -191559.08, -191787.0, -191923.94]\n",
      "Cluster 13: Buildings [16] Federated round ---------- 5 / 5\n",
      "Return:  -192186.72\n",
      "Performance List:  [-192186.72]\n",
      "Cluster 14: Buildings [10] Federated round ---------- 5 / 5\n",
      "Return:  -192275.78\n",
      "Performance List:  [-192275.78]\n",
      "Cluster 15: Buildings [27] Federated round ---------- 5 / 5\n",
      "Return:  -192180.08\n",
      "Performance List:  [-192180.08]\n",
      "Cluster 16: Buildings [25] Federated round ---------- 5 / 5\n",
      "Return:  -192159.4\n",
      "Performance List:  [-192159.4]\n",
      "Cluster 17: Buildings [ 5 12] Federated round ---------- 5 / 5\n",
      "Return:  4459.9136\n",
      "Return:  -14192.187\n",
      "Performance List:  [4459.9136, -14192.187]\n"
     ]
    }
   ],
   "source": [
    "#Start Federated Learning - For each federated round\n",
    "for federated_round  in range(federated_rounds):\n",
    "    \n",
    "    #Iterate through each cluster\n",
    "    for cluster_number, buildings_in_cluster in cluster_buildings.items():\n",
    "        print(f\"Cluster {cluster_number}: Buildings {buildings_in_cluster} Federated round ----------\", federated_round+1, f\"/ {federated_rounds}\")\n",
    "        \n",
    "        local_actor_weight_list = list()\n",
    "        local_critic_weight_list = list()\n",
    "        local_target_actor_weight_list = list()\n",
    "        local_target_critic_weight_list = list()\n",
    "\n",
    "        performance_metrics = list()\n",
    "\n",
    "        #Iterate through the buildings per cluster\n",
    "        for building_index in buildings_in_cluster:\n",
    "            \n",
    "            #0. Reset global step\n",
    "            tf.compat.v1.reset_default_graph()\n",
    "            global_step = tf.compat.v1.train.get_or_create_global_step()\n",
    "            \n",
    "            #1. Initalize local agent and set global weights\n",
    "            local_tf_agent, local_eval_policy, local_collect_policy = get_ddpg_agent(\n",
    "                observation_spec = environments[\"train\"][f\"building_{building_index}\"].observation_spec(),\n",
    "                action_spec = environments[\"train\"][f\"building_{building_index}\"].action_spec(),\n",
    "                custom_layers = [CustomLayers.get_dense_layers(layers=1, units=32)],\n",
    "                global_step = global_step,\n",
    "                environments = environments,\n",
    "                )\n",
    "            \n",
    "            model_dir = os.path.join(os.getcwd(), f\"models/cluster_{cluster_number}/FLround{federated_round}_c{num_clusters}_WAAwN\")\n",
    "            \n",
    "            with np.load(os.path.join(model_dir, \"actor_network_weights.npz\"), allow_pickle=True) as data:\n",
    "                # Extract the arrays using the keys corresponding to their order\n",
    "                local_tf_agent._actor_network.set_weights([data[f'arr_{i}'] for i in range(len(data.files))])\n",
    "            \n",
    "            with np.load(os.path.join(model_dir, \"critic_weights.npz\"), allow_pickle=True) as data:\n",
    "                # Extract the arrays using the keys corresponding to their order\n",
    "                local_tf_agent._critic_network.set_weights([data[f'arr_{i}'] for i in range(len(data.files))])\n",
    "            \n",
    "            with np.load(os.path.join(model_dir, \"target_actor_weights.npz\"), allow_pickle=True) as data:\n",
    "                # Extract the arrays using the keys corresponding to their order\n",
    "                local_tf_agent._target_actor_network.set_weights([data[f'arr_{i}'] for i in range(len(data.files))])\n",
    "            \n",
    "            with np.load(os.path.join(model_dir, \"target_critic_weights.npz\"), allow_pickle=True) as data:\n",
    "                # Extract the arrays using the keys corresponding to their order\n",
    "                local_tf_agent._target_critic_network.set_weights([data[f'arr_{i}'] for i in range(len(data.files))])\n",
    "\n",
    "            #2. Prepare training pipeline: Setup iterator, replay buffer, driver\n",
    "            local_iterator, local_collect_driver, local_time_step, local_policy_state = setup_rl_training_pipeline(\n",
    "                local_tf_agent, environments[\"train\"][f\"building_{building_index}\"], \n",
    "                replay_buffer_capacity, local_collect_policy, initial_collect_steps, \n",
    "                collect_steps_per_iteration, batch_size\n",
    "                )\n",
    "\n",
    "            #3. Setup wandb logging\n",
    "            #artifact = initialize_wandb_logging(name=f\"Exp_building{building_index}_rd{federated_round+1}\", num_iterations=num_iterations)\n",
    "\n",
    "            #4. Start training\n",
    "            #print(f\"Start training building {building_index+1} - Round {federated_round+1}\")\n",
    "            \n",
    "            eval_metrics = [tf_metrics.AverageReturnMetric()]\n",
    "            test_metrics = [tf_metrics.AverageReturnMetric()]\n",
    "\n",
    "            while global_step.numpy() < num_iterations:\n",
    "\n",
    "                #if global_step.numpy() % 50 == 0:\n",
    "                #    print(global_step.numpy(), \"/ \", num_iterations)\n",
    "\n",
    "                local_time_step, local_policy_state = local_collect_driver.run(time_step=local_time_step, policy_state=local_policy_state)\n",
    "                local_experience, _ = next(local_iterator)\n",
    "                local_train_loss = local_tf_agent.train(local_experience)\n",
    "                \n",
    "                \"\"\"metrics = {}\n",
    "                if global_step.numpy() % eval_interval == 0:\n",
    "                    #train_checkpointer.save(global_step)\n",
    "                    metrics = metric_utils.eager_compute(eval_metrics,environments[\"eval\"][f\"building_{building_index}\"],\n",
    "                        local_eval_policy,num_episodes=1,train_step=global_step,summary_writer=None,summary_prefix='',use_function=True)\"\"\"\n",
    "                \n",
    "                \n",
    "                #performance_metrics.append()\n",
    "                #if global_step.numpy() % 2 == 0:\n",
    "                #    metrics[\"loss\"] = local_train_loss.loss\n",
    "                #    wandb.log(metrics)\n",
    "            \n",
    "            metrics = metric_utils.eager_compute(test_metrics,environments[\"eval\"][f\"building_{building_index}\"], local_eval_policy, num_episodes=1)\n",
    "            print(\"Return: \", metrics[\"AverageReturn\"].numpy())\n",
    "            performance_metrics.append(metrics[\"AverageReturn\"].numpy())\n",
    "            \n",
    "            #5. Add local agent weights to list\n",
    "            local_actor_weight_list.append(local_tf_agent._actor_network.get_weights())\n",
    "            local_critic_weight_list.append(local_tf_agent._critic_network.get_weights())\n",
    "            local_target_actor_weight_list.append(local_tf_agent._target_actor_network.get_weights())\n",
    "            local_target_critic_weight_list.append(local_tf_agent._target_critic_network.get_weights())\n",
    "\n",
    "        # Performe Federated aggregation\n",
    "        print(\"Performance List: \", performance_metrics)\n",
    "        average_actor_weights = federated_aggregation(local_actor_weight_list, performance_metrics)\n",
    "        average_critic_weights = federated_aggregation(local_critic_weight_list, performance_metrics) \n",
    "        average_target_actor_weights = federated_aggregation(local_target_actor_weight_list, performance_metrics) \n",
    "        average_target_critic_weights = federated_aggregation(local_target_critic_weight_list, performance_metrics)    \n",
    "        \n",
    "        model_dir = os.path.join(os.getcwd(), f\"models/cluster_{cluster_number}/FLround{federated_round+1}_c{num_clusters}_WAAwN\")\n",
    "        os.makedirs(model_dir, exist_ok=True)\n",
    "\n",
    "        np.savez(os.path.join(model_dir, \"actor_network_weights.npz\"), *average_actor_weights)\n",
    "        np.savez(os.path.join(model_dir, \"critic_weights.npz\"), *average_critic_weights)\n",
    "        np.savez(os.path.join(model_dir, \"target_actor_weights.npz\"), *average_target_actor_weights)\n",
    "        np.savez(os.path.join(model_dir, \"target_critic_weights.npz\"), *average_target_critic_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cluster:  0  - Building:  7  - round:  0\n",
      "Building:  7  - Total Profit:  -32.98025289999993\n",
      "Cluster:  1  - Building:  17  - round:  0\n",
      "Building:  17  - Total Profit:  -368.7726228178648\n",
      "Cluster:  2  - Building:  13  - round:  0\n",
      "Building:  13  - Total Profit:  -40.75914236999963\n",
      "Cluster:  2  - Building:  19  - round:  0\n",
      "Building:  19  - Total Profit:  -30.16532673\n",
      "Cluster:  2  - Building:  20  - round:  0\n",
      "Building:  20  - Total Profit:  -256.3630751799992\n",
      "Cluster:  3  - Building:  18  - round:  0\n",
      "Building:  18  - Total Profit:  -311.63190151000015\n",
      "Cluster:  4  - Building:  9  - round:  0\n",
      "Building:  9  - Total Profit:  -134.22545635999936\n",
      "Cluster:  4  - Building:  30  - round:  0\n",
      "Building:  30  - Total Profit:  -101.18343558999989\n",
      "Cluster:  5  - Building:  1  - round:  0\n",
      "Building:  1  - Total Profit:  -25.610377677865184\n",
      "Cluster:  6  - Building:  6  - round:  0\n",
      "Building:  6  - Total Profit:  -596.944248857862\n",
      "Cluster:  7  - Building:  11  - round:  0\n",
      "Building:  11  - Total Profit:  -193.07766243786517\n",
      "Cluster:  8  - Building:  23  - round:  0\n",
      "Building:  23  - Total Profit:  -159.35406553786467\n",
      "Cluster:  8  - Building:  24  - round:  0\n",
      "Building:  24  - Total Profit:  156.6608824800007\n",
      "Cluster:  8  - Building:  26  - round:  0\n",
      "Building:  26  - Total Profit:  -379.2261962378658\n",
      "Cluster:  8  - Building:  28  - round:  0\n",
      "Building:  28  - Total Profit:  -119.26967464786554\n",
      "Cluster:  8  - Building:  29  - round:  0\n",
      "Building:  29  - Total Profit:  -174.24797369999996\n",
      "Cluster:  9  - Building:  2  - round:  0\n",
      "Building:  2  - Total Profit:  -209.5131475999992\n",
      "Cluster:  10  - Building:  8  - round:  0\n",
      "Building:  8  - Total Profit:  -615.7244323278647\n",
      "Cluster:  11  - Building:  21  - round:  0\n",
      "Building:  21  - Total Profit:  -412.8670945678671\n",
      "Cluster:  12  - Building:  3  - round:  0\n",
      "Building:  3  - Total Profit:  -12.30461181000009\n",
      "Cluster:  12  - Building:  4  - round:  0\n",
      "Building:  4  - Total Profit:  -174.97668204999962\n",
      "Cluster:  12  - Building:  14  - round:  0\n",
      "Building:  14  - Total Profit:  -131.51196755000015\n",
      "Cluster:  12  - Building:  15  - round:  0\n",
      "Building:  15  - Total Profit:  -106.74116607999937\n",
      "Cluster:  12  - Building:  22  - round:  0\n",
      "Building:  22  - Total Profit:  -156.78034535999973\n",
      "Cluster:  13  - Building:  16  - round:  0\n",
      "Building:  16  - Total Profit:  -161.0366269000002\n",
      "Cluster:  14  - Building:  10  - round:  0\n",
      "Building:  10  - Total Profit:  -185.63984823786467\n",
      "Cluster:  15  - Building:  27  - round:  0\n",
      "Building:  27  - Total Profit:  -211.25490086786579\n",
      "Cluster:  16  - Building:  25  - round:  0\n",
      "Building:  25  - Total Profit:  -299.453226607865\n",
      "Cluster:  17  - Building:  5  - round:  0\n",
      "Building:  5  - Total Profit:  214.91212797297757\n",
      "Cluster:  17  - Building:  12  - round:  0\n",
      "Building:  12  - Total Profit:  190.39627194721047\n"
     ]
    }
   ],
   "source": [
    "num_rounds=1\n",
    "num_test_iterations = 10000 # Ab 12 clustern, vorher 5000\n",
    "\n",
    "result_df = pd.DataFrame(columns=['Building', 'Total Profit'])\n",
    "\n",
    "for cluster_number, buildings_in_cluster in cluster_buildings.items():\n",
    "\n",
    "    for building_index in buildings_in_cluster:\n",
    "        \n",
    "        for round in range(num_rounds):\n",
    "            print(\"Cluster: \", cluster_number, \" - Building: \", building_index, \" - round: \", round)\n",
    "            \n",
    "            #0. Reset global step\n",
    "            tf.compat.v1.reset_default_graph()\n",
    "            global_step = tf.compat.v1.train.get_or_create_global_step()\n",
    "\n",
    "            #1. Initalize local agent and set trained global weights\n",
    "            federated_tf_agent, federated_eval_policy, federated_collect_policy = get_ddpg_agent(\n",
    "                observation_spec = environments[\"train\"][f\"building_{building_index}\"].observation_spec(),\n",
    "                action_spec = environments[\"train\"][f\"building_{building_index}\"].action_spec(),\n",
    "                custom_layers = [CustomLayers.get_dense_layers(layers=1, units=32)],\n",
    "                global_step = global_step,\n",
    "                environments = environments,\n",
    "                )\n",
    "            \n",
    "            model_dir = os.path.join(os.getcwd(), f\"models/cluster_{cluster_number}/FLround{3}_c{num_clusters}_WAAwN\")\n",
    "            with np.load(os.path.join(model_dir, \"actor_network_weights.npz\"), allow_pickle=True) as data:\n",
    "                # Extract the arrays using the keys corresponding to their order\n",
    "                federated_tf_agent._actor_network.set_weights([data[f'arr_{i}'] for i in range(len(data.files))])\n",
    "            \n",
    "            with np.load(os.path.join(model_dir, \"critic_weights.npz\"), allow_pickle=True) as data:\n",
    "                # Extract the arrays using the keys corresponding to their order\n",
    "                federated_tf_agent._critic_network.set_weights([data[f'arr_{i}'] for i in range(len(data.files))])\n",
    "            \n",
    "            with np.load(os.path.join(model_dir, \"target_actor_weights.npz\"), allow_pickle=True) as data:\n",
    "                # Extract the arrays using the keys corresponding to their order\n",
    "                federated_tf_agent._target_actor_network.set_weights([data[f'arr_{i}'] for i in range(len(data.files))])\n",
    "            \n",
    "            with np.load(os.path.join(model_dir, \"target_critic_weights.npz\"), allow_pickle=True) as data:\n",
    "                # Extract the arrays using the keys corresponding to their order\n",
    "                federated_tf_agent._target_critic_network.set_weights([data[f'arr_{i}'] for i in range(len(data.files))])\n",
    "            \n",
    "            #Setup iterator, replay buffer, driver\n",
    "            iterator, collect_driver, time_step, policy_state = setup_rl_training_pipeline(\n",
    "                federated_tf_agent, environments[\"train\"][f\"building_{building_index}\"], \n",
    "                replay_buffer_capacity, federated_collect_policy, initial_collect_steps, \n",
    "                collect_steps_per_iteration, batch_size\n",
    "                )\n",
    "            \n",
    "            #Setup wandb logging\n",
    "            artifact = initialize_wandb_logging(name=f\"Exp_building{building_index}_rd{round}\", num_iterations=num_iterations)\n",
    "            \n",
    "            #2. Train and evaluate\n",
    "            eval_metrics = [tf_metrics.AverageReturnMetric()]\n",
    "            test_metrics = [tf_metrics.AverageReturnMetric()]\n",
    "\n",
    "            while global_step.numpy() < num_test_iterations:\n",
    "\n",
    "                #if global_step.numpy() % 50 == 0:\n",
    "                #    print(global_step.numpy(), \"/ \", num_iterations)\n",
    "\n",
    "                time_step, policy_state = collect_driver.run(time_step=time_step, policy_state=policy_state)\n",
    "                experience, _ = next(iterator)\n",
    "                train_loss = federated_tf_agent.train(experience)\n",
    "                                \n",
    "                metrics = {}\n",
    "                if global_step.numpy() % eval_interval == 0:\n",
    "                    #train_checkpointer.save(global_step)\n",
    "                    metrics = metric_utils.eager_compute(eval_metrics,environments[\"eval\"][f\"building_{building_index}\"],\n",
    "                        federated_eval_policy,num_episodes=1,train_step=global_step,summary_writer=None,summary_prefix='',use_function=True)\n",
    "                \n",
    "                if global_step.numpy() % 2 == 0:\n",
    "                    metrics[\"loss\"] = train_loss.loss\n",
    "                    wandb.log(metrics)\n",
    "\n",
    "            #3. Start testing\n",
    "            metrics = metric_utils.eager_compute(test_metrics,environments[\"test\"][f\"building_{building_index}\"], federated_eval_policy, num_episodes=1)\n",
    "            print('Building: ', building_index, ' - Total Profit: ', wandb.summary[\"Final Profit\"])\n",
    "            result_df = pd.concat([result_df, pd.DataFrame({'Building': [building_index], 'Total Profit': [wandb.summary[\"Final Profit\"]]})], ignore_index=True)\n",
    "            wandb.log(metrics)\n",
    "            #artifact.add_dir(local_path='checkpoints/ddpg/')\n",
    "            wandb.log_artifact(artifact)\n",
    "            wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename column\n",
    "result_df.rename(columns={'Total Profit': 'Profit'}, inplace=True)\n",
    "result_df['Setup'] = f'cluster{num_clusters}'\n",
    "result_df.index.name = 'Building_nr'\n",
    "result_df.reset_index(inplace=True, drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final reuslt - clusters  18 :  -5039.646180114189\n"
     ]
    }
   ],
   "source": [
    "result_df.to_csv(f'results_clusters{num_clusters}_df.csv', index=False)\n",
    "print(\"Final reuslt - clusters \", num_clusters, \": \", result_df[\"Profit\"].sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cluster 2:  -5884.21237239078\n",
      "Cluster 6:  -5892.741336364493\n",
      "Cluster 10:  -5469.377397423285\n",
      "Cluster 12:  -5469.109807054782\n",
      "Cluster 14:  -5053.687516458025\n"
     ]
    }
   ],
   "source": [
    "print(\"Cluster 2: \", pd.read_csv(\"results_clusters2_df.csv\")[\"Profit\"].sum())\n",
    "print(\"Cluster 6: \", pd.read_csv(\"results_clusters6_df.csv\")[\"Profit\"].sum())\n",
    "print(\"Cluster 10: \", pd.read_csv(\"results_clusters10_df.csv\")[\"Profit\"].sum())\n",
    "print(\"Cluster 12: \", pd.read_csv(\"results_clusters12_df.csv\")[\"Profit\"].sum())\n",
    "print(\"Cluster 14: \", pd.read_csv(\"results_clusters14_df.csv\")[\"Profit\"].sum())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
