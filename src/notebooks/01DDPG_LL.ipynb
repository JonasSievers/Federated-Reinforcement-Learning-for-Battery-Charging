{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\rs1044\\Documents\\GitHub\\Federated-Reinforcement-Learning-for-Battery-Charging\\.venv\\lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n",
      "WARNING:tensorflow:From c:\\Users\\rs1044\\Documents\\GitHub\\Federated-Reinforcement-Learning-for-Battery-Charging\\.venv\\lib\\site-packages\\tensorflow_probability\\python\\internal\\backend\\numpy\\_utils.py:48: The name tf.logging.TaskLevelStatusMessage is deprecated. Please use tf.compat.v1.logging.TaskLevelStatusMessage instead.\n",
      "\n",
      "WARNING:tensorflow:From c:\\Users\\rs1044\\Documents\\GitHub\\Federated-Reinforcement-Learning-for-Battery-Charging\\.venv\\lib\\site-packages\\tensorflow_probability\\python\\internal\\backend\\numpy\\_utils.py:48: The name tf.control_flow_v2_enabled is deprecated. Please use tf.compat.v1.control_flow_v2_enabled instead.\n",
      "\n",
      "WARNING:tensorflow:From c:\\Users\\rs1044\\Documents\\GitHub\\Federated-Reinforcement-Learning-for-Battery-Charging\\.venv\\lib\\site-packages\\tf_agents\\typing\\types.py:114: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Imports\n",
    "import os\n",
    "import logging\n",
    "import pandas as pd\n",
    "import wandb\n",
    "import tensorflow as tf\n",
    "\n",
    "logging.getLogger(\"wandb\").setLevel(logging.ERROR)\n",
    "os.environ['WANDB_SILENT'] = 'true'\n",
    "os.environ['WANDB_CONSOLE'] = 'off'\n",
    "\n",
    "import sys\n",
    "sys.path.insert(0, '..')\n",
    "from utils.reinforcementLearningHelper import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch size: 1 / State Space: 6 / Action Space: 1 / Upper bound: 2.3\n"
     ]
    }
   ],
   "source": [
    "#Setup Environments of selected buildings for training, evaluation, and testing\n",
    "\n",
    "environments, observation_spec, action_spec  = setup_energymanagement_environments(num_buildings=30)\n",
    "\n",
    "#Check environment setup\n",
    "print(\n",
    "    \"Batch size:\", environments[\"train\"][f\"building_1\"].batch_size, \n",
    "    \"/ State Space: {} / Action Space: {}\".format(observation_spec.shape[0], action_spec.shape[0]),\n",
    "    \"/ Upper bound: {}\".format(round(environments[\"train\"][f\"building_1\"].action_spec().maximum.item(), 3)),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup Agent networks\n",
    "SEED = 42\n",
    "tf.random.set_seed(SEED)\n",
    "\n",
    "batch_size = 128\n",
    "replay_buffer_capacity = 20000 \n",
    "initial_collect_steps = 2000\n",
    "collect_steps_per_iteration = 20 \n",
    "num_iterations = 10000 \n",
    "eval_interval = 9990\n",
    "\n",
    "num_rounds = 1\n",
    "num_buildings = 30\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building:  0  - round:  0\n",
      "WARNING:tensorflow:From c:\\Users\\rs1044\\Documents\\GitHub\\Federated-Reinforcement-Learning-for-Battery-Charging\\.venv\\lib\\site-packages\\keras\\src\\backend.py:873: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "WARNING:tensorflow:From c:\\Users\\rs1044\\Documents\\GitHub\\Federated-Reinforcement-Learning-for-Battery-Charging\\.venv\\lib\\site-packages\\tensorflow\\python\\autograph\\impl\\api.py:377: ReplayBuffer.get_next (from tf_agents.replay_buffers.replay_buffer) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `as_dataset(..., single_deterministic_pass=False) instead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\rs1044\\Documents\\GitHub\\Federated-Reinforcement-Learning-for-Battery-Charging\\src\\notebooks\\..\\utils\\reinforcementLearningHelper.py:222: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  result_df = pd.concat([result_df, pd.DataFrame({'Building': [building_index], 'Total Profit': [wandb.summary[\"Final Profit\"]]})], ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building:  1  - Total Profit:  400.536776894932\n",
      "Building:  1  - round:  0\n",
      "Building:  2  - Total Profit:  204.85313796763657\n",
      "Building:  2  - round:  0\n",
      "WARNING:tensorflow:5 out of the last 5 calls to <function AverageReturnMetric.reset at 0x000001A133F71120> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:5 out of the last 5 calls to <bound method DynamicEpisodeDriver.run of <tf_agents.drivers.dynamic_episode_driver.DynamicEpisodeDriver object at 0x000001A133CCF3D0>> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:5 out of the last 5 calls to <function TFDeque.mean at 0x000001A133F73370> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:6 out of the last 6 calls to <function AverageReturnMetric.reset at 0x000001A133F73490> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:6 out of the last 6 calls to <bound method DynamicEpisodeDriver.run of <tf_agents.drivers.dynamic_episode_driver.DynamicEpisodeDriver object at 0x000001A133F9CA30>> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:6 out of the last 6 calls to <function TFDeque.mean at 0x000001A133F55EA0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Building:  3  - Total Profit:  409.36931454500143\n",
      "Building:  3  - round:  0\n"
     ]
    }
   ],
   "source": [
    "# LOCAL LEARNING\n",
    "\n",
    "result_df = pd.DataFrame(columns=['Building', 'Total Profit'])\n",
    "\n",
    "for idx in range(num_buildings):\n",
    "    for round in range(num_rounds):\n",
    "        building_index=idx+1\n",
    "        print(\"Building: \", building_index, \" - round: \", round)\n",
    "        #0. Reset global step\n",
    "        tf.compat.v1.reset_default_graph()\n",
    "        global_step = tf.compat.v1.train.get_or_create_global_step()\n",
    "        \n",
    "        #1. Initalize agent\n",
    "        tf_agent, eval_policy, collect_policy = initialize_ddpg_agent(observation_spec, action_spec, global_step, environments)\n",
    "\n",
    "        #2. Prepare training pipeline: Setup iterator, replay buffer, driver\n",
    "        iterator, collect_driver, time_step, policy_state = setup_rl_training_pipeline(\n",
    "            tf_agent, environments[\"train\"][f\"building_{building_index}\"], replay_buffer_capacity,collect_policy, \n",
    "            initial_collect_steps, collect_steps_per_iteration, batch_size\n",
    "            )\n",
    "\n",
    "        #3. Setup wandb logging\n",
    "        artifact = initialize_wandb_logging(name=f\"Exp_DDPG_LL_Home{building_index}_rd{round}\", num_iterations=num_iterations)\n",
    "\n",
    "        #4. Train, evaluate agent and store weights\n",
    "        result_df, metrics = ddpg_training_and_evaluation(global_step, num_iterations, collect_driver, \n",
    "                time_step, policy_state, iterator, tf_agent, eval_policy, building_index, result_df, eval_interval, environments)\n",
    "            \n",
    "        #6. End and log wandb\n",
    "        end_and_log_wandb(metrics, artifact)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
