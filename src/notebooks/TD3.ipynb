{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tf_agents.agents import ddpg\n",
    "from tf_agents.agents.td3 import td3_agent\n",
    "from tf_agents.drivers import dynamic_step_driver\n",
    "from tf_agents.environments import tf_py_environment\n",
    "from tf_agents.eval import metric_utils\n",
    "from tf_agents.metrics import tf_metrics\n",
    "from tf_agents.replay_buffers import tf_uniform_replay_buffer\n",
    "from tf_agents.utils import common\n",
    "\n",
    "import sys\n",
    "sys.path.insert(0, '..')\n",
    "import utils.dataloader as dataloader\n",
    "import Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Param for iteration\n",
    "num_iterations = 10000\n",
    "\n",
    "# Params for collect\n",
    "initial_collect_steps = 1000\n",
    "collect_steps_per_iteration = 1000\n",
    "replay_buffer_capacity = 1000000\n",
    "ou_stddev = 0.2\n",
    "ou_damping = 0.15\n",
    "\n",
    "# Params for target update\n",
    "target_update_tau = 0.05\n",
    "target_update_period = 5\n",
    "\n",
    "# Params for train\n",
    "exploration_noise_std = 0.1\n",
    "actor_update_period = 2\n",
    "train_steps_per_iteration = 1\n",
    "batch_size = 1000\n",
    "actor_learning_rate = 1e-4\n",
    "critic_learning_rate = 1e-3\n",
    "dqda_clipping = None\n",
    "td_errors_loss_fn = tf.compat.v1.losses.huber_loss\n",
    "gamma = 0.99\n",
    "reward_scale_factor = 1.0\n",
    "gradient_clipping = None\n",
    "\n",
    "# Params for eval and checkpoints\n",
    "num_eval_episodes = 1\n",
    "eval_interval = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "data_train = dataloader.get_customer_data(dataloader.loadData('../../data/load1011.csv'),\n",
    "                                          dataloader.loadPrice('../../data/price.csv'), 1)\n",
    "data_eval = dataloader.get_customer_data(dataloader.loadData('../../data/load1112.csv'),\n",
    "                                         dataloader.loadPrice('../../data/price.csv'), 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare runner\n",
    "global_step = tf.compat.v1.train.get_or_create_global_step()\n",
    "\n",
    "tf_env = tf_py_environment.TFPyEnvironment(Environment.Environment(init_charge=10.0, data=data_train))\n",
    "tf_env_eval = tf_py_environment.TFPyEnvironment(Environment.Environment(init_charge=10.0, data=data_eval))\n",
    "\n",
    "actor_net = ddpg.actor_network.ActorNetwork(input_tensor_spec=tf_env.observation_spec(),\n",
    "                                           output_tensor_spec=tf_env.action_spec(), fc_layer_params=(400, 300),\n",
    "                                           activation_fn=tf.keras.activations.relu)\n",
    "\n",
    "critic_net = ddpg.critic_network.CriticNetwork(input_tensor_spec=(tf_env.observation_spec(), tf_env.action_spec()),\n",
    "                                              joint_fc_layer_params=(400, 300),\n",
    "                                              activation_fn=tf.keras.activations.relu)\n",
    "\n",
    "tf_agent = td3_agent.Td3Agent(\n",
    "    tf_env.time_step_spec(),\n",
    "    tf_env.action_spec(),\n",
    "    actor_network=actor_net,\n",
    "    critic_network=critic_net,\n",
    "    actor_optimizer=tf.compat.v1.train.AdamOptimizer(\n",
    "        learning_rate=actor_learning_rate\n",
    "    ),\n",
    "    critic_optimizer=tf.compat.v1.train.AdamOptimizer(\n",
    "        learning_rate=critic_learning_rate\n",
    "    ),\n",
    "    exploration_noise_std=exploration_noise_std,\n",
    "    target_update_tau=target_update_tau,\n",
    "    target_update_period=target_update_period,\n",
    "    actor_update_period=actor_update_period,\n",
    "    td_errors_loss_fn=td_errors_loss_fn,\n",
    "    gamma=gamma,\n",
    "    reward_scale_factor=reward_scale_factor,\n",
    "    gradient_clipping=gradient_clipping,\n",
    "    debug_summaries=False,\n",
    "    summarize_grads_and_vars=False,\n",
    "    train_step_counter=global_step,\n",
    ")\n",
    "\n",
    "tf_agent.initialize()\n",
    "\n",
    "eval_policy = tf_agent.policy\n",
    "collect_policy = tf_agent.collect_policy\n",
    "\n",
    "replay_buffer = tf_uniform_replay_buffer.TFUniformReplayBuffer(\n",
    "    tf_agent.collect_data_spec,\n",
    "    batch_size=tf_env.batch_size,\n",
    "    max_length=replay_buffer_capacity,\n",
    ")\n",
    "\n",
    "initial_collect_driver = dynamic_step_driver.DynamicStepDriver(\n",
    "    tf_env,\n",
    "    collect_policy,\n",
    "    observers=[replay_buffer.add_batch],\n",
    "    num_steps=initial_collect_steps,\n",
    ")\n",
    "\n",
    "collect_driver = dynamic_step_driver.DynamicStepDriver(\n",
    "    tf_env,\n",
    "    collect_policy,\n",
    "    observers=[replay_buffer.add_batch],\n",
    "    num_steps=collect_steps_per_iteration,\n",
    ")\n",
    "\n",
    "train_checkpointer = common.Checkpointer(\n",
    "    ckpt_dir='./checkpoints/td3/',\n",
    "    max_to_keep=1,\n",
    "    agent=tf_agent,\n",
    "    policy=tf_agent.policy,\n",
    "    replay_buffer=replay_buffer,\n",
    "    global_step=global_step\n",
    ")\n",
    "\n",
    "eval_summary_writer = tf.compat.v2.summary.create_file_writer(\n",
    "    logdir='./log/td3/', flush_millis=10000\n",
    ")\n",
    "\n",
    "eval_metrics = [\n",
    "    tf_metrics.AverageReturnMetric(buffer_size=num_eval_episodes)\n",
    "]\n",
    "\n",
    "train_checkpointer.initialize_or_restore()\n",
    "global_step = tf.compat.v1.train.get_global_step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For better performance\n",
    "initial_collect_driver.run = common.function(initial_collect_driver.run)\n",
    "collect_driver.run = common.function(collect_driver.run)\n",
    "tf_agent.train = common.function(tf_agent.train)\n",
    "\n",
    "# Collect initial replay data\n",
    "initial_collect_driver.run()\n",
    "\n",
    "time_step = tf_env.reset()\n",
    "policy_state = collect_policy.get_initial_state(tf_env.batch_size)\n",
    "\n",
    "# Dataset generates trajectories with shape [Bx2x...]\n",
    "# pipeline which will feed data to the agent\n",
    "dataset = replay_buffer.as_dataset(\n",
    "    num_parallel_calls=3, sample_batch_size=batch_size, num_steps=2\n",
    ").prefetch(3)\n",
    "iterator = iter(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.compat.v2.summary.record_if(True):\n",
    "    metric_utils.eager_compute(\n",
    "        eval_metrics,\n",
    "        tf_env_eval,\n",
    "        eval_policy,\n",
    "        num_episodes=num_eval_episodes,\n",
    "        train_step=global_step,\n",
    "        summary_writer=eval_summary_writer,\n",
    "        summary_prefix='Metrics')\n",
    "\n",
    "    # Train and evaluate\n",
    "    while global_step.numpy() <= num_iterations:\n",
    "        time_step, policy_state = collect_driver.run(\n",
    "            time_step=time_step,\n",
    "            policy_state=policy_state,\n",
    "        )\n",
    "        experience, _ = next(iterator)\n",
    "        train_loss = tf_agent.train(experience)\n",
    "        print('step = {0}: Loss = {1}'.format(global_step.numpy(), train_loss.loss))\n",
    "        with eval_summary_writer.as_default():\n",
    "            tf.summary.scalar(name='loss', data=train_loss.loss, step=global_step)\n",
    "        if global_step.numpy() % eval_interval == 0:\n",
    "            train_checkpointer.save(global_step)\n",
    "            metric_utils.eager_compute(\n",
    "                eval_metrics,\n",
    "                tf_env_eval,\n",
    "                eval_policy,\n",
    "                num_episodes=num_eval_episodes,\n",
    "                train_step=global_step,\n",
    "                summary_writer=eval_summary_writer,\n",
    "                summary_prefix='Metrics')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test\n",
    "data_test = dataloader.get_customer_data(dataloader.loadData('./data/load1213.csv'),\n",
    "                                         dataloader.loadPrice('./data/price.csv'), 1)\n",
    "tf_env_test = tf_py_environment.TFPyEnvironment(Environment.Environment(init_charge=10.0, data=data_test, test=True))\n",
    "time_step_test = tf_env_test.reset()\n",
    "\n",
    "while not time_step_test.is_last():\n",
    "    action_step = tf_agent.policy.action(time_step_test)\n",
    "    time_step_test = tf_env_test.step(action_step.action)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
