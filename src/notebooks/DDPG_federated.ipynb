{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\rs1044\\Documents\\GitHub\\Federated-Reinforcement-Learning-for-Battery-Charging\\.venv\\lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\rs1044\\AppData\\Local\\Temp\\ipykernel_24268\\2142354254.py:18: The name tf.logging.set_verbosity is deprecated. Please use tf.compat.v1.logging.set_verbosity instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Imports\n",
    "\n",
    "import logging\n",
    "import os\n",
    "logging.getLogger(\"wandb\").setLevel(logging.ERROR)\n",
    "logging.getLogger('tensorflow').setLevel(logging.ERROR)\n",
    "os.environ['WANDB_SILENT'] = 'true'\n",
    "os.environ['WANDB_CONSOLE'] = 'off'\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "import tensorflow as tf\n",
    "tf.compat.v1.logging.set_verbosity(tf.compat.v1.logging.ERROR)\n",
    "from tf_agents.agents.ddpg import ddpg_agent\n",
    "from tf_agents.drivers import dynamic_step_driver\n",
    "from tf_agents.environments import tf_py_environment, py_environment, batched_py_environment\n",
    "from tf_agents.eval import metric_utils\n",
    "from tf_agents.metrics import tf_metrics\n",
    "from tf_agents.replay_buffers import tf_uniform_replay_buffer\n",
    "from tf_agents.utils import common\n",
    "import matplotlib.pyplot as plt\n",
    "import wandb\n",
    "\n",
    "import sys\n",
    "sys.path.insert(0, '..')\n",
    "from environments.EnergyManagementEnv import EnergyManagementEnv\n",
    "from utils.agentNetworks import ActorNetwork, CriticNetwork, CustomLayers\n",
    "import utils.dataloader as DL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch size:  1\n",
      "State Space: 6, Action Space: 1\n",
      "Upper bound: 2.3\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>load_1</th>\n",
       "      <th>pv_1</th>\n",
       "      <th>price</th>\n",
       "      <th>fuelmix</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.149</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.05704</td>\n",
       "      <td>0.530991</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   load_1  pv_1    price   fuelmix\n",
       "0   1.149   0.0  0.05704  0.530991"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_buildings = 30\n",
    "energy_data = pd.read_csv(\"../../data/3final_data/Final_Energy_dataset.csv\", header=0)\n",
    "energy_data.set_index('Date', inplace=True)\n",
    "energy_data.fillna(0, inplace=True)\n",
    "\n",
    "dataset = {\"train\": {}, \"eval\": {}, \"test\": {}}\n",
    "environments = {\"train\": {}, \"eval\": {}, \"test\": {}}\n",
    "for idx in range(num_buildings):\n",
    "    user_data = energy_data[[f'load_{idx+1}', f'pv_{idx+1}', 'price', 'fuelmix']]\n",
    "    \n",
    "    dataset[\"train\"][f\"building_{idx+1}\"] = user_data[0:17520].set_index(pd.RangeIndex(0,17520))\n",
    "    dataset[\"eval\"][f\"building_{idx+1}\"] = user_data[17520:35088].set_index(pd.RangeIndex(0,17568))\n",
    "    dataset[\"test\"][f\"building_{idx+1}\"] = user_data[35088:52608].set_index(pd.RangeIndex(0,17520))\n",
    "\n",
    "    environments[\"train\"][f\"building_{idx+1}\"] = tf_py_environment.TFPyEnvironment(EnergyManagementEnv(init_charge=0.0, data=dataset[\"train\"][f\"building_{idx+1}\"]))\n",
    "    environments[\"eval\"][f\"building_{idx+1}\"] = tf_py_environment.TFPyEnvironment(EnergyManagementEnv(init_charge=0.0, data=dataset[\"eval\"][f\"building_{idx+1}\"]))\n",
    "    environments[\"test\"][f\"building_{idx+1}\"] = tf_py_environment.TFPyEnvironment(EnergyManagementEnv(init_charge=0.0, data=dataset[\"test\"][f\"building_{idx+1}\"]))\n",
    "\n",
    "print(\"Batch size: \", environments[\"train\"][f\"building_1\"].batch_size)\n",
    "print(\"State Space: {}, Action Space: {}\".format(environments[\"train\"][f\"building_1\"].observation_spec().shape[0], environments[\"train\"][f\"building_1\"].action_spec().shape[0])) #SoE, price, price forecast 1-6\n",
    "print(\"Upper bound: {}\".format(round(environments[\"train\"][f\"building_1\"].action_spec().maximum.item(), 3)))\n",
    "dataset[\"test\"][f\"building_1\"].head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Federated Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "federated_rounds = 3\n",
    "num_rounds = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: array([ 7, 14, 18, 22, 23, 25, 29], dtype=int64),\n",
       " 1: array([6], dtype=int64),\n",
       " 2: array([ 3,  4,  9, 13, 15, 19, 20, 30], dtype=int64),\n",
       " 3: array([1], dtype=int64),\n",
       " 4: array([21], dtype=int64),\n",
       " 5: array([ 2, 28], dtype=int64),\n",
       " 6: array([ 5, 10, 11, 12, 24, 26, 27], dtype=int64),\n",
       " 7: array([8], dtype=int64),\n",
       " 8: array([17], dtype=int64),\n",
       " 9: array([16], dtype=int64)}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = np.loadtxt(f'../../data/3final_data/Clusters_KMeans10_dtw.csv', delimiter=',').astype(int)\n",
    "num_clusters = 10\n",
    "cluster_users = {i: [] for i in range(num_clusters)}\n",
    "\n",
    "# Iterate through each cluster\n",
    "for cluster_number in range(num_clusters):\n",
    "    users_in_cluster = np.where(y == cluster_number)[0] +1\n",
    "    cluster_users[cluster_number] = users_in_cluster\n",
    "cluster_users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def avg_weights_with_noise_fedprox(weight_list, clip_threshold=None, noise_scale=0.001, proximal_term=0.1):\n",
    "    avg_grad = list()\n",
    "\n",
    "    for grad_list_tuple in zip(*weight_list):\n",
    "        layer_mean = tf.math.reduce_mean(grad_list_tuple, axis=0)\n",
    "\n",
    "        if clip_threshold is not None:\n",
    "            layer_mean = tf.clip_by_value(layer_mean, -clip_threshold, clip_threshold)\n",
    "\n",
    "        noise = tf.random.normal(shape=layer_mean.shape, mean=0.0, stddev=noise_scale)\n",
    "        noisy_layer_mean = layer_mean + noise\n",
    "\n",
    "        # Add FedProx proximal term\n",
    "        proximal_update = -proximal_term * noisy_layer_mean\n",
    "\n",
    "        avg_grad.append(noisy_layer_mean + proximal_update)\n",
    "\n",
    "    return avg_grad"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Federated Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cluster:  0\n",
      "Started Federated training round ---------- 1 / 3\n",
      "Cluster 0:\n",
      "User index:  7\n",
      "Start training building 7\n",
      "0 /  10\n",
      "1 /  10\n",
      "2 /  10\n",
      "3 /  10\n",
      "4 /  10\n",
      "5 /  10\n",
      "6 /  10\n",
      "7 /  10\n",
      "8 /  10\n",
      "9 /  10\n",
      "User index:  14\n",
      "Start training building 14\n",
      "User index:  18\n",
      "Start training building 18\n",
      "User index:  22\n",
      "Start training building 22\n",
      "User index:  23\n"
     ]
    }
   ],
   "source": [
    "tf.compat.v1.reset_default_graph()\n",
    "\n",
    "batch_size = 1\n",
    "replay_buffer_capacity = 100000\n",
    "initial_collect_steps = 1000\n",
    "collect_steps_per_iteration = 1000 #2000\n",
    "num_iterations = 10 #1500\n",
    "\n",
    "weights = {\"actor_net\": {}, \"critic_net\": {}, \"target_actor_network\": {}, \"target_critic_network\": {}}\n",
    "\n",
    "for cluster in range(num_clusters):\n",
    "    #Build and save global model\n",
    "    print(\"Cluster: \", cluster)\n",
    "    \n",
    "    # 1. Build global networks\n",
    "    global_step = tf.compat.v1.train.create_global_step()\n",
    "    first_building_in_cluster = cluster_users[cluster][0]\n",
    "\n",
    "    global_actor_net = ActorNetwork(\n",
    "        observation_spec=environments[\"train\"][f\"building_{1}\"].observation_spec(),\n",
    "        action_spec=environments[\"train\"][f\"building_{1}\"].action_spec(),\n",
    "        custom_layers=[CustomLayers.get_dense_layers(layers=1, units=4)],\n",
    "        )\n",
    "\n",
    "    global_critic_net = CriticNetwork(\n",
    "        observation_spec=environments[\"train\"][f\"building_{first_building_in_cluster}\"].observation_spec(),\n",
    "        action_spec=environments[\"train\"][f\"building_{first_building_in_cluster}\"].action_spec(),\n",
    "        custom_layers=[CustomLayers.get_dense_layers(layers=1, units=4)],\n",
    "        )\n",
    "\n",
    "    global_target_actor_network = ActorNetwork(\n",
    "        observation_spec=environments[\"train\"][f\"building_{first_building_in_cluster}\"].observation_spec(),\n",
    "        action_spec=environments[\"train\"][f\"building_{first_building_in_cluster}\"].action_spec(),\n",
    "        custom_layers=[CustomLayers.get_dense_layers(layers=1, units=4)],\n",
    "        )\n",
    "\n",
    "    global_target_critic_network = CriticNetwork(\n",
    "        observation_spec=environments[\"train\"][f\"building_{first_building_in_cluster}\"].observation_spec(),\n",
    "        action_spec=environments[\"train\"][f\"building_{first_building_in_cluster}\"].action_spec(),\n",
    "        custom_layers=[CustomLayers.get_dense_layers(layers=1, units=4)],\n",
    "        )\n",
    "\n",
    "    tf_agent = ddpg_agent.DdpgAgent(\n",
    "        environments[\"train\"][f\"building_{first_building_in_cluster}\"].time_step_spec(),\n",
    "        environments[\"train\"][f\"building_{first_building_in_cluster}\"].action_spec(),\n",
    "        actor_network= global_actor_net,\n",
    "        critic_network= global_critic_net,\n",
    "        actor_optimizer=tf.compat.v1.train.AdamOptimizer(learning_rate=1e-4), #-2 bis -4\n",
    "        critic_optimizer=tf.compat.v1.train.AdamOptimizer(learning_rate=1e-3), #-1 bis -3\n",
    "        ou_stddev=0.2, #0.3, # 0.2 , 0.3,\n",
    "        ou_damping=0.15, #0.15, #0.15,\n",
    "        target_actor_network= global_target_actor_network,\n",
    "        target_critic_network= global_target_critic_network,\n",
    "        target_update_tau=0.05, # 0.005, 0.01, 0.05,\n",
    "        target_update_period=10, # 5, 20, 50\n",
    "        dqda_clipping=1,\n",
    "        td_errors_loss_fn= tf.compat.v1.losses.huber_loss, #tf.keras.losses.MeanSquaredError(),\n",
    "        gamma=0.99, # 0.9, 0.99\n",
    "        reward_scale_factor=10, # 1.0,\n",
    "        train_step_counter=global_step,\n",
    "    )\n",
    "\n",
    "    tf_agent.initialize()\n",
    "    collect_policy = tf_agent.collect_policy\n",
    "    \n",
    "    # 2. Store weights\n",
    "    weights[\"actor_net\"][cluster] = global_actor_net.get_weights()\n",
    "    weights[\"critic_net\"][cluster] = global_critic_net.get_weights()\n",
    "    weights[\"target_actor_network\"][cluster] = global_target_actor_network.get_weights()\n",
    "    weights[\"target_critic_network\"][cluster] = global_target_critic_network.get_weights()\n",
    "\n",
    "    for federated_round  in range(federated_rounds):\n",
    "        print(\"Started Federated training round ----------\", federated_round+1, f\"/ {federated_rounds}\")\n",
    "        for cluster_number, users_in_cluster in cluster_users.items():\n",
    "            print(f\"Cluster {cluster_number}:\")\n",
    "            for user_index in users_in_cluster:\n",
    "                tf.compat.v1.reset_default_graph()\n",
    "                print(\"User index: \", user_index)\n",
    "                \n",
    "                #Actor setup\n",
    "                local_actor_net = ActorNetwork(\n",
    "                    observation_spec=environments[\"train\"][f\"building_{1}\"].observation_spec(),\n",
    "                    action_spec=environments[\"train\"][f\"building_{1}\"].action_spec(),\n",
    "                    custom_layers=[CustomLayers.get_dense_layers(layers=1, units=4)],\n",
    "                    )\n",
    "                \n",
    "                weights_list = [weights[\"actor_net\"][cluster] for cluster in weights[\"actor_net\"]]\n",
    "                averaged_weights  = avg_weights_with_noise_fedprox(weights_list)\n",
    "                #Build\n",
    "                dummy_observation = tf.random.uniform(shape=[1] + environments[\"train\"][f\"building_{first_building_in_cluster}\"].observation_spec().shape)\n",
    "                _ = local_actor_net(dummy_observation)\n",
    "                local_actor_net.set_weights(averaged_weights)\n",
    "\n",
    "                #Critic setup\n",
    "                local_critic_net = CriticNetwork(\n",
    "                    observation_spec=environments[\"train\"][f\"building_{first_building_in_cluster}\"].observation_spec(),\n",
    "                    action_spec=environments[\"train\"][f\"building_{first_building_in_cluster}\"].action_spec(),\n",
    "                    custom_layers=[CustomLayers.get_dense_layers(layers=1, units=4)],\n",
    "                    )\n",
    "                weights_list = [weights[\"critic_net\"][cluster] for cluster in weights[\"critic_net\"]]\n",
    "                averaged_weights  = avg_weights_with_noise_fedprox(weights_list)\n",
    "                #Build\n",
    "                observation_spec = environments[\"train\"][f\"building_{first_building_in_cluster}\"].observation_spec()\n",
    "                dummy_observation = tf.random.uniform(shape=[1] + observation_spec.shape)\n",
    "                action_spec = environments[\"train\"][f\"building_{first_building_in_cluster}\"].action_spec()\n",
    "                dummy_action = tf.random.uniform(shape=[1] + list(action_spec.shape), minval=action_spec.minimum, maxval=action_spec.maximum)\n",
    "                dummy_input = (dummy_observation, dummy_action)\n",
    "                _ = local_critic_net(dummy_input)\n",
    "                local_critic_net.set_weights(averaged_weights)\n",
    "\n",
    "                #Target actor setup\n",
    "                local_target_actor_network = ActorNetwork(\n",
    "                    observation_spec=environments[\"train\"][f\"building_{first_building_in_cluster}\"].observation_spec(),\n",
    "                    action_spec=environments[\"train\"][f\"building_{first_building_in_cluster}\"].action_spec(),\n",
    "                    custom_layers=[CustomLayers.get_dense_layers(layers=1, units=4)],\n",
    "                    )\n",
    "                weights_list = [weights[\"target_actor_network\"][cluster] for cluster in weights[\"target_actor_network\"]]\n",
    "                averaged_weights  = avg_weights_with_noise_fedprox(weights_list)\n",
    "                #Build\n",
    "                dummy_observation = tf.random.uniform(shape=[1] + environments[\"train\"][f\"building_{first_building_in_cluster}\"].observation_spec().shape)\n",
    "                _ = local_target_actor_network(dummy_observation)\n",
    "                local_target_actor_network.set_weights(averaged_weights)\n",
    "\n",
    "                local_target_critic_network = CriticNetwork(\n",
    "                    observation_spec=environments[\"train\"][f\"building_{first_building_in_cluster}\"].observation_spec(),\n",
    "                    action_spec=environments[\"train\"][f\"building_{first_building_in_cluster}\"].action_spec(),\n",
    "                    custom_layers=[CustomLayers.get_dense_layers(layers=1, units=4)],\n",
    "                    )\n",
    "                weights_list = [weights[\"target_critic_network\"][cluster] for cluster in weights[\"target_critic_network\"]]\n",
    "                averaged_weights  = avg_weights_with_noise_fedprox(weights_list)\n",
    "                #Build\n",
    "                observation_spec = environments[\"train\"][f\"building_{first_building_in_cluster}\"].observation_spec()\n",
    "                dummy_observation = tf.random.uniform(shape=[1] + observation_spec.shape)\n",
    "                action_spec = environments[\"train\"][f\"building_{first_building_in_cluster}\"].action_spec()\n",
    "                dummy_action = tf.random.uniform(shape=[1] + list(action_spec.shape), minval=action_spec.minimum, maxval=action_spec.maximum)\n",
    "                dummy_input = (dummy_observation, dummy_action)\n",
    "                _ = local_target_critic_network(dummy_input)\n",
    "                local_target_critic_network.set_weights(averaged_weights)\n",
    "\n",
    "                local_tf_agent = ddpg_agent.DdpgAgent(\n",
    "                    environments[\"train\"][f\"building_{first_building_in_cluster}\"].time_step_spec(),\n",
    "                    environments[\"train\"][f\"building_{first_building_in_cluster}\"].action_spec(),\n",
    "                    actor_network= global_actor_net,\n",
    "                    critic_network= global_critic_net,\n",
    "                    actor_optimizer=tf.compat.v1.train.AdamOptimizer(learning_rate=1e-4), #-2 bis -4\n",
    "                    critic_optimizer=tf.compat.v1.train.AdamOptimizer(learning_rate=1e-3), #-1 bis -3\n",
    "                    ou_stddev=0.2, #0.3, # 0.2 , 0.3,\n",
    "                    ou_damping=0.15, #0.15, #0.15,\n",
    "                    target_actor_network= global_target_actor_network,\n",
    "                    target_critic_network= global_target_critic_network,\n",
    "                    target_update_tau=0.05, # 0.005, 0.01, 0.05,\n",
    "                    target_update_period=10, # 5, 20, 50\n",
    "                    dqda_clipping=1,\n",
    "                    td_errors_loss_fn= tf.compat.v1.losses.huber_loss, #tf.keras.losses.MeanSquaredError(),\n",
    "                    gamma=0.99, # 0.9, 0.99\n",
    "                    reward_scale_factor=10, # 1.0,\n",
    "                    train_step_counter=global_step,\n",
    "                )\n",
    "                # Setup for training\n",
    "                replay_buffer = tf_uniform_replay_buffer.TFUniformReplayBuffer(\n",
    "                    data_spec=tf_agent.collect_data_spec,\n",
    "                    batch_size= environments[\"train\"][f\"building_{user_index}\"].batch_size,\n",
    "                    max_length=replay_buffer_capacity,\n",
    "                )\n",
    "\n",
    "                initial_collect_driver = dynamic_step_driver.DynamicStepDriver(\n",
    "                    environments[\"train\"][f\"building_{user_index}\"],\n",
    "                    collect_policy,\n",
    "                    observers=[replay_buffer.add_batch],\n",
    "                    num_steps=initial_collect_steps,\n",
    "                )\n",
    "\n",
    "                collect_driver = dynamic_step_driver.DynamicStepDriver(\n",
    "                    environments[\"train\"][f\"building_{user_index}\"],\n",
    "                    collect_policy,\n",
    "                    observers=[replay_buffer.add_batch],\n",
    "                    num_steps=collect_steps_per_iteration,\n",
    "                )\n",
    "\n",
    "                wandb.login()\n",
    "                wandb.init(\n",
    "                    project=\"DDPG_battery_testing\",\n",
    "                    job_type=\"train_eval_test\",\n",
    "                    name=f\"Exp_building{user_index}\",\n",
    "                    config={\n",
    "                        \"train_steps\": num_iterations,\n",
    "                        \"batch_size\": batch_size,\n",
    "                        \"actor_learning_rate\": 1e-4,\n",
    "                        \"critic_learning_rate\": 1e-3}\n",
    "                )\n",
    "                artifact = wandb.Artifact(name='save', type=\"checkpoint\")\n",
    "\n",
    "                eval_metrics = [tf_metrics.AverageReturnMetric(batch_size=batch_size)]\n",
    "                test_metrics = [tf_metrics.AverageReturnMetric(batch_size=batch_size)]\n",
    "\n",
    "                initial_collect_driver.run = common.function(initial_collect_driver.run)\n",
    "                collect_driver.run = common.function(collect_driver.run)\n",
    "                tf_agent.train = common.function(tf_agent.train)\n",
    "\n",
    "                # Collect initial replay data\n",
    "                initial_collect_driver.run()\n",
    "                time_step = environments[\"train\"][f\"building_{user_index}\"].reset()\n",
    "                policy_state = collect_policy.get_initial_state(environments[\"train\"][f\"building_{user_index}\"].batch_size)\n",
    "\n",
    "                # pipeline which will feed data to the agent\n",
    "                dataset = replay_buffer.as_dataset(num_parallel_calls=3, sample_batch_size=batch_size, num_steps=2).prefetch(3)\n",
    "                iterator = iter(dataset)\n",
    "                \n",
    "                # Train and evaluate\n",
    "                print(f\"Start training building {user_index}\")\n",
    "                while global_step.numpy() < num_iterations:\n",
    "                    print(global_step.numpy(), \"/ \", num_iterations)\n",
    "                    time_step, policy_state = collect_driver.run(\n",
    "                        time_step=time_step,\n",
    "                        policy_state=policy_state,\n",
    "                    )\n",
    "                    experience, _ = next(iterator)\n",
    "                    train_loss = tf_agent.train(experience)\n",
    "\n",
    "                    if global_step.numpy() % 2 == 0:\n",
    "                        metrics = {}    \n",
    "                        metrics[\"Loss\"] = train_loss.loss\n",
    "                        wandb.log(metrics)\n",
    "                \n",
    "                \n",
    "                weights[\"actor_net\"][cluster] = tf_agent._actor_network.get_weights()\n",
    "                weights[\"critic_net\"][cluster] = tf_agent._critic_network.get_weights()\n",
    "                weights[\"target_actor_network\"][cluster] = tf_agent._target_actor_network.get_weights()  # Assuming protected access\n",
    "                weights[\"target_critic_network\"][cluster] = tf_agent._target_critic_network.get_weights()  # Assuming protected access\n",
    "                tf.compat.v1.reset_default_graph()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Start testing ...\")\n",
    "metrics = metric_utils.eager_compute(\n",
    "    test_metrics,\n",
    "    environments[\"test\"][f\"building_{idx+1}\"],\n",
    "    tf_agent.policy,\n",
    "    num_episodes=batch_size)\n",
    "logging = {}    \n",
    "logging[\"AverageReturn\"] = metrics['AverageReturn'].numpy()\n",
    "wandb.log(logging)\n",
    "#artifact.add_dir(local_path='checkpoints/ddpg/')\n",
    "wandb.log_artifact(artifact)\n",
    "wandb.finish()\n",
    "tf.compat.v1.reset_default_graph()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
