{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\rs1044\\Documents\\GitHub\\Federated-Reinforcement-Learning-for-Battery-Charging\\.venv\\lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\rs1044\\AppData\\Local\\Temp\\ipykernel_25608\\3749357545.py:18: The name tf.logging.set_verbosity is deprecated. Please use tf.compat.v1.logging.set_verbosity instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Imports\n",
    "\n",
    "import logging\n",
    "import os\n",
    "logging.getLogger(\"wandb\").setLevel(logging.ERROR)\n",
    "logging.getLogger('tensorflow').setLevel(logging.ERROR)\n",
    "os.environ['WANDB_SILENT'] = 'true'\n",
    "os.environ['WANDB_CONSOLE'] = 'off'\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "import tensorflow as tf\n",
    "tf.compat.v1.logging.set_verbosity(tf.compat.v1.logging.ERROR)\n",
    "#from tf_agents.agents.ddpg import ddpg_agent\n",
    "#from tf_agents.drivers import dynamic_step_driver\n",
    "from tf_agents.environments import tf_py_environment\n",
    "from tf_agents.eval import metric_utils\n",
    "from tf_agents.metrics import tf_metrics\n",
    "#from tf_agents.replay_buffers import tf_uniform_replay_buffer\n",
    "#from tf_agents.utils import common\n",
    "import matplotlib.pyplot as plt\n",
    "import wandb\n",
    "\n",
    "import sys\n",
    "sys.path.insert(0, '..')\n",
    "from environments.EnergyManagementEnv import EnergyManagementEnv\n",
    "from utils.agentNetworks import ActorNetwork, CriticNetwork, CustomLayers\n",
    "#import utils.dataloader as DL\n",
    "from utils.federatedLearningHandler import *\n",
    "from utils.federatedAggregation import FederatedAggregation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch size:  1\n",
      "State Space: 6, Action Space: 1\n",
      "Upper bound: 2.3\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>load_1</th>\n",
       "      <th>pv_1</th>\n",
       "      <th>price</th>\n",
       "      <th>fuelmix</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.149</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.05704</td>\n",
       "      <td>0.530991</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   load_1  pv_1    price   fuelmix\n",
       "0   1.149   0.0  0.05704  0.530991"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Create Environments\n",
    "\n",
    "num_buildings = 30\n",
    "energy_data = pd.read_csv(\"../../data/3final_data/Final_Energy_dataset.csv\", header=0)\n",
    "energy_data.set_index('Date', inplace=True)\n",
    "energy_data.fillna(0, inplace=True)\n",
    "\n",
    "dataset = {\"train\": {}, \"eval\": {}, \"test\": {}}\n",
    "environments = {\"train\": {}, \"eval\": {}, \"test\": {}}\n",
    "for idx in range(num_buildings):\n",
    "    user_data = energy_data[[f'load_{idx+1}', f'pv_{idx+1}', 'price', 'fuelmix']]\n",
    "    \n",
    "    dataset[\"train\"][f\"building_{idx+1}\"] = user_data[0:17520].set_index(pd.RangeIndex(0,17520))\n",
    "    dataset[\"eval\"][f\"building_{idx+1}\"] = user_data[17520:35088].set_index(pd.RangeIndex(0,17568))\n",
    "    dataset[\"test\"][f\"building_{idx+1}\"] = user_data[35088:52608].set_index(pd.RangeIndex(0,17520))\n",
    "\n",
    "    environments[\"train\"][f\"building_{idx+1}\"] = tf_py_environment.TFPyEnvironment(EnergyManagementEnv(init_charge=0.0, data=dataset[\"train\"][f\"building_{idx+1}\"]))\n",
    "    environments[\"eval\"][f\"building_{idx+1}\"] = tf_py_environment.TFPyEnvironment(EnergyManagementEnv(init_charge=0.0, data=dataset[\"eval\"][f\"building_{idx+1}\"]))\n",
    "    environments[\"test\"][f\"building_{idx+1}\"] = tf_py_environment.TFPyEnvironment(EnergyManagementEnv(init_charge=0.0, data=dataset[\"test\"][f\"building_{idx+1}\"], logging=True))\n",
    "\n",
    "print(\"Batch size: \", environments[\"train\"][f\"building_1\"].batch_size)\n",
    "print(\"State Space: {}, Action Space: {}\".format(environments[\"train\"][f\"building_1\"].observation_spec().shape[0], environments[\"train\"][f\"building_1\"].action_spec().shape[0])) #SoE, price, price forecast 1-6\n",
    "print(\"Upper bound: {}\".format(round(environments[\"train\"][f\"building_1\"].action_spec().maximum.item(), 3)))\n",
    "dataset[\"test\"][f\"building_1\"].head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: array([7], dtype=int64),\n",
       " 1: array([16, 17, 21], dtype=int64),\n",
       " 2: array([13, 19, 20], dtype=int64),\n",
       " 3: array([18], dtype=int64),\n",
       " 4: array([ 3,  4,  9, 14, 15, 22, 30], dtype=int64),\n",
       " 5: array([1], dtype=int64),\n",
       " 6: array([6, 8], dtype=int64),\n",
       " 7: array([11], dtype=int64),\n",
       " 8: array([ 5, 12, 23, 24, 25, 26, 27, 28, 29], dtype=int64),\n",
       " 9: array([ 2, 10], dtype=int64)}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Clustering\n",
    "num_clusters = 10 # 2, 6, 10, 12, 14, 16, 18\n",
    "\n",
    "# Setup Agent networks\n",
    "federated_rounds = 5\n",
    "batch_size = 128\n",
    "replay_buffer_capacity = 20000 #-> only <18.000 samples per dataset\n",
    "initial_collect_steps = 2000\n",
    "collect_steps_per_iteration = 20 \n",
    "num_iterations = 10000 #10000\n",
    "eval_interval = 9500 #3000\n",
    "\n",
    "\n",
    "y = np.loadtxt(f'../../data/3final_data/Clusters_KMeans_dtw_c{num_clusters}.csv', delimiter=',').astype(int)\n",
    "cluster_buildings = {i: [] for i in range(num_clusters)}\n",
    "\n",
    "# Iterate through each cluster\n",
    "for cluster_number in range(num_clusters):\n",
    "    buildings_in_cluster = np.where(y == cluster_number)[0] +1\n",
    "    cluster_buildings[cluster_number] = buildings_in_cluster\n",
    "cluster_buildings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initial Federated Learning Round -> Setup Global models per cluster\n",
    "global_weights = {\"actor_net\": {}, \"critic_net\": {}, \"target_actor_network\": {}, \"target_critic_network\": {}}\n",
    "\n",
    "#Initalize a global model for each Cluster of similar buildings\n",
    "for cluster in range(num_clusters):\n",
    "        # 1. Build global agent per cluster\n",
    "        tf.compat.v1.reset_default_graph()\n",
    "        global_step = tf.compat.v1.train.get_or_create_global_step()\n",
    "        first_building_in_cluster = cluster_buildings[cluster][0]\n",
    "\n",
    "        global_tf_agent, global_eval_policy, global_collect_policy = get_ddpg_agent(\n",
    "                observation_spec = environments[\"train\"][f\"building_{first_building_in_cluster}\"].observation_spec(),\n",
    "                action_spec = environments[\"train\"][f\"building_{first_building_in_cluster}\"].action_spec(),\n",
    "                custom_layers = [CustomLayers.get_dense_layers(layers=1, units=32)],\n",
    "                global_step = global_step,\n",
    "                environments = environments,\n",
    "                )\n",
    "\n",
    "        # 2. Initially store weights\n",
    "        global_weights[\"actor_net\"][cluster] = global_tf_agent._actor_network.get_weights()\n",
    "        global_weights[\"critic_net\"][cluster] = global_tf_agent._critic_network.get_weights()\n",
    "        global_weights[\"target_actor_network\"][cluster] = global_tf_agent._target_actor_network.get_weights()\n",
    "        global_weights[\"target_critic_network\"][cluster] = global_tf_agent._target_critic_network.get_weights()\n",
    "\n",
    "        model_dir = os.path.join(os.getcwd(), f\"models/cluster_{cluster}/FLround{0}_c{num_clusters}_AvgAgg\")\n",
    "        os.makedirs(model_dir, exist_ok=True)\n",
    "\n",
    "        np.savez(os.path.join(model_dir, \"actor_network_weights.npz\"), *global_tf_agent._actor_network.get_weights())\n",
    "        np.savez(os.path.join(model_dir, \"critic_weights.npz\"), *global_tf_agent._critic_network.get_weights())\n",
    "        np.savez(os.path.join(model_dir, \"target_actor_weights.npz\"), *global_tf_agent._target_actor_network.get_weights())\n",
    "        np.savez(os.path.join(model_dir, \"target_critic_weights.npz\"), *global_tf_agent._target_critic_network.get_weights())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cluster 0: Buildings [7] Federated round ---------- 1 / 5\n",
      "Return:  4950.34\n",
      "Performance List:  [4950.34]\n",
      "Cluster 1: Buildings [16 17 21] Federated round ---------- 1 / 5\n",
      "Return:  4313.71\n",
      "Return:  4168.073\n",
      "Return:  3503.0078\n",
      "Performance List:  [4313.71, 4168.073, 3503.0078]\n",
      "Cluster 2: Buildings [13 19 20] Federated round ---------- 1 / 5\n",
      "Return:  4940.148\n",
      "Return:  4798.8726\n",
      "Return:  4680.468\n",
      "Performance List:  [4940.148, 4798.8726, 4680.468]\n",
      "Cluster 3: Buildings [18] Federated round ---------- 1 / 5\n",
      "Return:  4224.5947\n",
      "Performance List:  [4224.5947]\n",
      "Cluster 4: Buildings [ 3  4  9 14 15 22 30] Federated round ---------- 1 / 5\n",
      "Return:  4701.213\n",
      "Return:  4386.02\n",
      "Return:  4458.8794\n",
      "Return:  4852.931\n",
      "Return:  4613.528\n",
      "Return:  4428.125\n",
      "Return:  4630.5806\n",
      "Performance List:  [4701.213, 4386.02, 4458.8794, 4852.931, 4613.528, 4428.125, 4630.5806]\n",
      "Cluster 5: Buildings [1] Federated round ---------- 1 / 5\n",
      "Return:  5434.9473\n",
      "Performance List:  [5434.9473]\n",
      "Cluster 6: Buildings [6 8] Federated round ---------- 1 / 5\n",
      "Return:  4008.4446\n",
      "Return:  3147.2012\n",
      "Performance List:  [4008.4446, 3147.2012]\n",
      "Cluster 7: Buildings [11] Federated round ---------- 1 / 5\n",
      "Return:  4467.5083\n",
      "Performance List:  [4467.5083]\n",
      "Cluster 8: Buildings [ 5 12 23 24 25 26 27 28 29] Federated round ---------- 1 / 5\n",
      "Return:  4450.088\n",
      "Return:  4311.243\n",
      "Return:  4375.1816\n",
      "Return:  6494.5386\n",
      "Return:  4207.815\n",
      "Return:  4086.4365\n",
      "Return:  4223.543\n",
      "Return:  4483.0522\n",
      "Return:  4452.492\n",
      "Performance List:  [4450.088, 4311.243, 4375.1816, 6494.5386, 4207.815, 4086.4365, 4223.543, 4483.0522, 4452.492]\n",
      "Cluster 9: Buildings [ 2 10] Federated round ---------- 1 / 5\n",
      "Return:  4199.2295\n",
      "Return:  4130.506\n",
      "Performance List:  [4199.2295, 4130.506]\n",
      "Cluster 0: Buildings [7] Federated round ---------- 2 / 5\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Layer ActorNetwork weight shape (256,) is not compatible with provided weight shape (1, 256).",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 35\u001b[0m\n\u001b[0;32m     31\u001b[0m model_dir \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(os\u001b[38;5;241m.\u001b[39mgetcwd(), \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodels/cluster_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcluster_number\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/FLround\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfederated_round\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_c\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnum_clusters\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_AvgAgg\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     33\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m np\u001b[38;5;241m.\u001b[39mload(os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(model_dir, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mactor_network_weights.npz\u001b[39m\u001b[38;5;124m\"\u001b[39m), allow_pickle\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m data:\n\u001b[0;32m     34\u001b[0m     \u001b[38;5;66;03m# Extract the arrays using the keys corresponding to their order\u001b[39;00m\n\u001b[1;32m---> 35\u001b[0m     \u001b[43mlocal_tf_agent\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_actor_network\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mset_weights\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43marr_\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mi\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mrange\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfiles\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     37\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m np\u001b[38;5;241m.\u001b[39mload(os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(model_dir, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcritic_weights.npz\u001b[39m\u001b[38;5;124m\"\u001b[39m), allow_pickle\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m data:\n\u001b[0;32m     38\u001b[0m     \u001b[38;5;66;03m# Extract the arrays using the keys corresponding to their order\u001b[39;00m\n\u001b[0;32m     39\u001b[0m     local_tf_agent\u001b[38;5;241m.\u001b[39m_critic_network\u001b[38;5;241m.\u001b[39mset_weights([data[\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124marr_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(data\u001b[38;5;241m.\u001b[39mfiles))])\n",
      "File \u001b[1;32mc:\\Users\\rs1044\\Documents\\GitHub\\Federated-Reinforcement-Learning-for-Battery-Charging\\.venv\\lib\\site-packages\\keras\\src\\engine\\base_layer.py:1822\u001b[0m, in \u001b[0;36mLayer.set_weights\u001b[1;34m(self, weights)\u001b[0m\n\u001b[0;32m   1820\u001b[0m ref_shape \u001b[38;5;241m=\u001b[39m param\u001b[38;5;241m.\u001b[39mshape\n\u001b[0;32m   1821\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m ref_shape\u001b[38;5;241m.\u001b[39mis_compatible_with(weight_shape):\n\u001b[1;32m-> 1822\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m   1823\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLayer \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m weight shape \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mref_shape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1824\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mis not compatible with provided weight \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1825\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mshape \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mweight_shape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1826\u001b[0m     )\n\u001b[0;32m   1827\u001b[0m weight_value_tuples\u001b[38;5;241m.\u001b[39mappend((param, weight))\n\u001b[0;32m   1828\u001b[0m weight_index \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "\u001b[1;31mValueError\u001b[0m: Layer ActorNetwork weight shape (256,) is not compatible with provided weight shape (1, 256)."
     ]
    }
   ],
   "source": [
    "#Start Federated Learning - For each federated round\n",
    "for federated_round  in range(federated_rounds):\n",
    "    \n",
    "    #Iterate through each cluster\n",
    "    for cluster_number, buildings_in_cluster in cluster_buildings.items():\n",
    "        print(f\"Cluster {cluster_number}: Buildings {buildings_in_cluster} Federated round ----------\", federated_round+1, f\"/ {federated_rounds}\")\n",
    "        \n",
    "        local_actor_weight_list = list()\n",
    "        local_critic_weight_list = list()\n",
    "        local_target_actor_weight_list = list()\n",
    "        local_target_critic_weight_list = list()\n",
    "\n",
    "        performance_metrics = list()\n",
    "\n",
    "        #Iterate through the buildings per cluster\n",
    "        for building_index in buildings_in_cluster:\n",
    "            \n",
    "            #0. Reset global step\n",
    "            tf.compat.v1.reset_default_graph()\n",
    "            global_step = tf.compat.v1.train.get_or_create_global_step()\n",
    "            \n",
    "            #1. Initalize local agent and set global weights\n",
    "            local_tf_agent, local_eval_policy, local_collect_policy = get_ddpg_agent(\n",
    "                observation_spec = environments[\"train\"][f\"building_{building_index}\"].observation_spec(),\n",
    "                action_spec = environments[\"train\"][f\"building_{building_index}\"].action_spec(),\n",
    "                custom_layers = [CustomLayers.get_dense_layers(layers=1, units=32)],\n",
    "                global_step = global_step,\n",
    "                environments = environments,\n",
    "                )\n",
    "            \n",
    "            model_dir = os.path.join(os.getcwd(), f\"models/cluster_{cluster_number}/FLround{federated_round}_c{num_clusters}_AvgAgg\")\n",
    "            \n",
    "            with np.load(os.path.join(model_dir, \"actor_network_weights.npz\"), allow_pickle=True) as data:\n",
    "                # Extract the arrays using the keys corresponding to their order\n",
    "                local_tf_agent._actor_network.set_weights([data[f'arr_{i}'] for i in range(len(data.files))])\n",
    "            \n",
    "            with np.load(os.path.join(model_dir, \"critic_weights.npz\"), allow_pickle=True) as data:\n",
    "                # Extract the arrays using the keys corresponding to their order\n",
    "                local_tf_agent._critic_network.set_weights([data[f'arr_{i}'] for i in range(len(data.files))])\n",
    "            \n",
    "            with np.load(os.path.join(model_dir, \"target_actor_weights.npz\"), allow_pickle=True) as data:\n",
    "                # Extract the arrays using the keys corresponding to their order\n",
    "                local_tf_agent._target_actor_network.set_weights([data[f'arr_{i}'] for i in range(len(data.files))])\n",
    "            \n",
    "            with np.load(os.path.join(model_dir, \"target_critic_weights.npz\"), allow_pickle=True) as data:\n",
    "                # Extract the arrays using the keys corresponding to their order\n",
    "                local_tf_agent._target_critic_network.set_weights([data[f'arr_{i}'] for i in range(len(data.files))])\n",
    "\n",
    "            #2. Prepare training pipeline: Setup iterator, replay buffer, driver\n",
    "            local_iterator, local_collect_driver, local_time_step, local_policy_state = setup_rl_training_pipeline(\n",
    "                local_tf_agent, environments[\"train\"][f\"building_{building_index}\"], \n",
    "                replay_buffer_capacity, local_collect_policy, initial_collect_steps, \n",
    "                collect_steps_per_iteration, batch_size\n",
    "                )\n",
    "\n",
    "            #3. Setup wandb logging\n",
    "            #artifact = initialize_wandb_logging(name=f\"Exp_building{building_index}_rd{federated_round+1}\", num_iterations=num_iterations)\n",
    "\n",
    "            #4. Start training\n",
    "            #print(f\"Start training building {building_index+1} - Round {federated_round+1}\")\n",
    "            \n",
    "            eval_metrics = [tf_metrics.AverageReturnMetric()]\n",
    "            test_metrics = [tf_metrics.AverageReturnMetric()]\n",
    "\n",
    "            while global_step.numpy() < num_iterations:\n",
    "\n",
    "                #if global_step.numpy() % 50 == 0:\n",
    "                #    print(global_step.numpy(), \"/ \", num_iterations)\n",
    "\n",
    "                local_time_step, local_policy_state = local_collect_driver.run(time_step=local_time_step, policy_state=local_policy_state)\n",
    "                local_experience, _ = next(local_iterator)\n",
    "                local_train_loss = local_tf_agent.train(local_experience)\n",
    "                \n",
    "                \"\"\"metrics = {}\n",
    "                if global_step.numpy() % eval_interval == 0:\n",
    "                    #train_checkpointer.save(global_step)\n",
    "                    metrics = metric_utils.eager_compute(eval_metrics,environments[\"eval\"][f\"building_{building_index}\"],\n",
    "                        local_eval_policy,num_episodes=1,train_step=global_step,summary_writer=None,summary_prefix='',use_function=True)\"\"\"\n",
    "                \n",
    "                \n",
    "                #performance_metrics.append()\n",
    "                #if global_step.numpy() % 2 == 0:\n",
    "                #    metrics[\"loss\"] = local_train_loss.loss\n",
    "                #    wandb.log(metrics)\n",
    "            \n",
    "            metrics = metric_utils.eager_compute(test_metrics,environments[\"eval\"][f\"building_{building_index}\"], \n",
    "                                                 local_eval_policy, num_episodes=1)\n",
    "            print(\"Return: \", metrics[\"AverageReturn\"].numpy())\n",
    "            performance_metrics.append(metrics[\"AverageReturn\"].numpy())\n",
    "            \n",
    "            #5. Add local agent weights to list\n",
    "            local_actor_weight_list.append(local_tf_agent._actor_network.get_weights())\n",
    "            local_critic_weight_list.append(local_tf_agent._critic_network.get_weights())\n",
    "            local_target_actor_weight_list.append(local_tf_agent._target_actor_network.get_weights())\n",
    "            local_target_critic_weight_list.append(local_tf_agent._target_critic_network.get_weights())\n",
    "\n",
    "        # Performe Federated aggregation\n",
    "        print(\"Performance List: \", performance_metrics)\n",
    "        average_actor_weights = FederatedAggregation.federated_weigthed_aggregation(local_actor_weight_list, performance_metrics)\n",
    "        average_critic_weights = FederatedAggregation.federated_weigthed_aggregation(local_critic_weight_list, performance_metrics) \n",
    "        average_target_actor_weights = FederatedAggregation.federated_weigthed_aggregation(local_target_actor_weight_list, performance_metrics) \n",
    "        average_target_critic_weights = FederatedAggregation.federated_weigthed_aggregation(local_target_critic_weight_list, performance_metrics)    \n",
    "        \n",
    "        model_dir = os.path.join(os.getcwd(), f\"models/cluster_{cluster_number}/FLround{federated_round+1}_c{num_clusters}_AvgAgg\")\n",
    "        os.makedirs(model_dir, exist_ok=True)\n",
    "\n",
    "        np.savez(os.path.join(model_dir, \"actor_network_weights.npz\"), *average_actor_weights)\n",
    "        np.savez(os.path.join(model_dir, \"critic_weights.npz\"), *average_critic_weights)\n",
    "        np.savez(os.path.join(model_dir, \"target_actor_weights.npz\"), *average_target_actor_weights)\n",
    "        np.savez(os.path.join(model_dir, \"target_critic_weights.npz\"), *average_target_critic_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cluster:  0  - Building:  7  - round:  0\n",
      "Building:  7  - Total Profit:  -32.98025289999993\n",
      "Cluster:  1  - Building:  17  - round:  0\n",
      "Building:  17  - Total Profit:  -368.7726228178648\n",
      "Cluster:  2  - Building:  13  - round:  0\n",
      "Building:  13  - Total Profit:  -40.75914236999963\n",
      "Cluster:  2  - Building:  19  - round:  0\n",
      "Building:  19  - Total Profit:  -30.16532673\n",
      "Cluster:  2  - Building:  20  - round:  0\n",
      "Building:  20  - Total Profit:  -256.3630751799992\n",
      "Cluster:  3  - Building:  18  - round:  0\n",
      "Building:  18  - Total Profit:  -311.63190151000015\n",
      "Cluster:  4  - Building:  9  - round:  0\n",
      "Building:  9  - Total Profit:  -134.22545635999936\n",
      "Cluster:  4  - Building:  30  - round:  0\n",
      "Building:  30  - Total Profit:  -101.18343558999989\n",
      "Cluster:  5  - Building:  1  - round:  0\n",
      "Building:  1  - Total Profit:  -25.610377677865184\n",
      "Cluster:  6  - Building:  6  - round:  0\n",
      "Building:  6  - Total Profit:  -596.944248857862\n",
      "Cluster:  7  - Building:  11  - round:  0\n",
      "Building:  11  - Total Profit:  -193.07766243786517\n",
      "Cluster:  8  - Building:  23  - round:  0\n",
      "Building:  23  - Total Profit:  -159.35406553786467\n",
      "Cluster:  8  - Building:  24  - round:  0\n",
      "Building:  24  - Total Profit:  156.6608824800007\n",
      "Cluster:  8  - Building:  26  - round:  0\n",
      "Building:  26  - Total Profit:  -379.2261962378658\n",
      "Cluster:  8  - Building:  28  - round:  0\n",
      "Building:  28  - Total Profit:  -119.26967464786554\n",
      "Cluster:  8  - Building:  29  - round:  0\n",
      "Building:  29  - Total Profit:  -174.24797369999996\n",
      "Cluster:  9  - Building:  2  - round:  0\n",
      "Building:  2  - Total Profit:  -209.5131475999992\n",
      "Cluster:  10  - Building:  8  - round:  0\n",
      "Building:  8  - Total Profit:  -615.7244323278647\n",
      "Cluster:  11  - Building:  21  - round:  0\n",
      "Building:  21  - Total Profit:  -412.8670945678671\n",
      "Cluster:  12  - Building:  3  - round:  0\n",
      "Building:  3  - Total Profit:  -12.30461181000009\n",
      "Cluster:  12  - Building:  4  - round:  0\n",
      "Building:  4  - Total Profit:  -174.97668204999962\n",
      "Cluster:  12  - Building:  14  - round:  0\n",
      "Building:  14  - Total Profit:  -131.51196755000015\n",
      "Cluster:  12  - Building:  15  - round:  0\n",
      "Building:  15  - Total Profit:  -106.74116607999937\n",
      "Cluster:  12  - Building:  22  - round:  0\n",
      "Building:  22  - Total Profit:  -156.78034535999973\n",
      "Cluster:  13  - Building:  16  - round:  0\n",
      "Building:  16  - Total Profit:  -161.0366269000002\n",
      "Cluster:  14  - Building:  10  - round:  0\n",
      "Building:  10  - Total Profit:  -185.63984823786467\n",
      "Cluster:  15  - Building:  27  - round:  0\n",
      "Building:  27  - Total Profit:  -211.25490086786579\n",
      "Cluster:  16  - Building:  25  - round:  0\n",
      "Building:  25  - Total Profit:  -299.453226607865\n",
      "Cluster:  17  - Building:  5  - round:  0\n",
      "Building:  5  - Total Profit:  214.91212797297757\n",
      "Cluster:  17  - Building:  12  - round:  0\n",
      "Building:  12  - Total Profit:  190.39627194721047\n"
     ]
    }
   ],
   "source": [
    "num_rounds=1\n",
    "num_test_iterations = 8000 # Ab 12 clustern, vorher 5000\n",
    "\n",
    "result_df = pd.DataFrame(columns=['Building', 'Total Profit'])\n",
    "\n",
    "for cluster_number, buildings_in_cluster in cluster_buildings.items():\n",
    "\n",
    "    for building_index in buildings_in_cluster:\n",
    "        \n",
    "        for round in range(num_rounds):\n",
    "            print(\"Cluster: \", cluster_number, \" - Building: \", building_index, \" - round: \", round)\n",
    "            \n",
    "            #0. Reset global step\n",
    "            tf.compat.v1.reset_default_graph()\n",
    "            global_step = tf.compat.v1.train.get_or_create_global_step()\n",
    "\n",
    "            #1. Initalize local agent and set trained global weights\n",
    "            federated_tf_agent, federated_eval_policy, federated_collect_policy = get_ddpg_agent(\n",
    "                observation_spec = environments[\"train\"][f\"building_{building_index}\"].observation_spec(),\n",
    "                action_spec = environments[\"train\"][f\"building_{building_index}\"].action_spec(),\n",
    "                custom_layers = [CustomLayers.get_dense_layers(layers=1, units=32)],\n",
    "                global_step = global_step,\n",
    "                environments = environments,\n",
    "                )\n",
    "            \n",
    "            model_dir = os.path.join(os.getcwd(), f\"models/cluster_{cluster_number}/FLround{3}_c{num_clusters}_AvgAgg\")\n",
    "            with np.load(os.path.join(model_dir, \"actor_network_weights.npz\"), allow_pickle=True) as data:\n",
    "                # Extract the arrays using the keys corresponding to their order\n",
    "                federated_tf_agent._actor_network.set_weights([data[f'arr_{i}'] for i in range(len(data.files))])\n",
    "            \n",
    "            with np.load(os.path.join(model_dir, \"critic_weights.npz\"), allow_pickle=True) as data:\n",
    "                # Extract the arrays using the keys corresponding to their order\n",
    "                federated_tf_agent._critic_network.set_weights([data[f'arr_{i}'] for i in range(len(data.files))])\n",
    "            \n",
    "            with np.load(os.path.join(model_dir, \"target_actor_weights.npz\"), allow_pickle=True) as data:\n",
    "                # Extract the arrays using the keys corresponding to their order\n",
    "                federated_tf_agent._target_actor_network.set_weights([data[f'arr_{i}'] for i in range(len(data.files))])\n",
    "            \n",
    "            with np.load(os.path.join(model_dir, \"target_critic_weights.npz\"), allow_pickle=True) as data:\n",
    "                # Extract the arrays using the keys corresponding to their order\n",
    "                federated_tf_agent._target_critic_network.set_weights([data[f'arr_{i}'] for i in range(len(data.files))])\n",
    "            \n",
    "            #Setup iterator, replay buffer, driver\n",
    "            iterator, collect_driver, time_step, policy_state = setup_rl_training_pipeline(\n",
    "                federated_tf_agent, environments[\"train\"][f\"building_{building_index}\"], \n",
    "                replay_buffer_capacity, federated_collect_policy, initial_collect_steps, \n",
    "                collect_steps_per_iteration, batch_size\n",
    "                )\n",
    "            \n",
    "            #Setup wandb logging\n",
    "            artifact = initialize_wandb_logging(name=f\"Exp_building{building_index}_rd{round}\", num_iterations=num_iterations)\n",
    "            \n",
    "            #2. Train and evaluate\n",
    "            eval_metrics = [tf_metrics.AverageReturnMetric()]\n",
    "            test_metrics = [tf_metrics.AverageReturnMetric()]\n",
    "\n",
    "            while global_step.numpy() < num_test_iterations:\n",
    "\n",
    "                #if global_step.numpy() % 50 == 0:\n",
    "                #    print(global_step.numpy(), \"/ \", num_iterations)\n",
    "\n",
    "                time_step, policy_state = collect_driver.run(time_step=time_step, policy_state=policy_state)\n",
    "                experience, _ = next(iterator)\n",
    "                train_loss = federated_tf_agent.train(experience)\n",
    "                                \n",
    "                metrics = {}\n",
    "                if global_step.numpy() % eval_interval == 0:\n",
    "                    #train_checkpointer.save(global_step)\n",
    "                    metrics = metric_utils.eager_compute(eval_metrics,environments[\"eval\"][f\"building_{building_index}\"],\n",
    "                        federated_eval_policy,num_episodes=1,train_step=global_step,summary_writer=None,summary_prefix='',use_function=True)\n",
    "                \n",
    "                if global_step.numpy() % 2 == 0:\n",
    "                    metrics[\"loss\"] = train_loss.loss\n",
    "                    wandb.log(metrics)\n",
    "\n",
    "            #3. Start testing\n",
    "            metrics = metric_utils.eager_compute(test_metrics,environments[\"test\"][f\"building_{building_index}\"], federated_eval_policy, num_episodes=1)\n",
    "            print('Building: ', building_index, ' - Total Profit: ', wandb.summary[\"Final Profit\"])\n",
    "            result_df = pd.concat([result_df, pd.DataFrame({'Building': [building_index], 'Total Profit': [wandb.summary[\"Final Profit\"]]})], ignore_index=True)\n",
    "            wandb.log(metrics)\n",
    "            #artifact.add_dir(local_path='checkpoints/ddpg/')\n",
    "            wandb.log_artifact(artifact)\n",
    "            wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final reuslt - clusters  18 :  -5039.646180114189\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cluster 2:  -5884.21237239078\n",
      "Cluster 6:  -5892.741336364493\n",
      "Cluster 10:  -5469.377397423285\n",
      "Cluster 12:  -5469.109807054782\n",
      "Cluster 14:  -5053.687516458025\n"
     ]
    }
   ],
   "source": [
    "print(\"Cluster 2: \", pd.read_csv(\"results_clusters2_df.csv\")[\"Profit\"].sum())\n",
    "print(\"Cluster 6: \", pd.read_csv(\"results_clusters6_df.csv\")[\"Profit\"].sum())\n",
    "print(\"Cluster 10: \", pd.read_csv(\"results_clusters10_df.csv\")[\"Profit\"].sum())\n",
    "print(\"Cluster 12: \", pd.read_csv(\"results_clusters12_df.csv\")[\"Profit\"].sum())\n",
    "print(\"Cluster 14: \", pd.read_csv(\"results_clusters14_df.csv\")[\"Profit\"].sum())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
